[{"content":"Fluent Python Owner: Huijie Liu Tags: Ongoing, Study Note\n数据结构 序列构成的数组 Python 标准库用 C 实现了丰富的序列类型，列举如下。\n容器序列 list、tuple 和 collections.deque 这些序列能存放不同类型的数据。 扁平序列 str、bytes、bytearray、memoryview 和 array.array，这类序列只能容纳一种类型。 容器序列存放的是它们所包含的任意类型的对象的引用，而扁平序列里存放的是值而不是 引用。换句话说，扁平序列其实是一段连续的内存空间。由此可见扁平序列其实更加紧 凑，但是它里面只能存放诸如字符、字节和数值这种基础类型。\n序列类型还能按照能否被修改来分类。\n可变序列 list、bytearray、array.array、collections.deque 和 memoryview。 不可变序列 tuple、str 和 bytes。 字典和集合 💡 **dict** 类型是 Python 语言的基石。模块的命名空间、 实例的属性和函数的关键字参数中都可以看到字典的身影。跟它有关的内置函数都在 __builtins__.__dict__ 模块中。 正是因为字典至关重要，Python 对它的实现做了高度优化，而散列表则是字典类型性能出 众的根本原因。集合(set)的实现其实也依赖于散列表。\n如果一个对象是可散列的，那么在这个对象的生命周期中，它的散列值是不变的，而且这个对象需要实现 hash() 方法。另外可散列对象还要有 eq() 方法，这样才能跟其他键做比较。如果两个可散列对象是相等的，那么它们的散列值一定是一样的。一般来讲用户自定义的类型的对象都是可散列的。\n文本和字节序列 把函数视作对象 💡 可以把函数赋值给变量、传给 其他函数、存储在数据结构中，以及访问函数的属性，供框架和一些工具使用。 一等函数 在 Python 中，函数是一等对象。编程语言理论家把“**一等对象”**定义为满足下述条件的程 序实体:\n在运行时创建 能赋值给变量或数据结构中的元素 能作为参数传给函数 能作为函数的返回结果 在 Python 中，整数、字符串和字典都是一等对象。\n高阶函数 接受函数为参数，或者把函数作为结果返回的函数是高阶函数。函数式语言通常会提供 map、filter 和 reduce 三个高阶函数。\n函数内省 除了 doc，函数对象还有很多属性。使用 dir 函数可以探知所有属性:\n调用函数时使用 * 和 **“展开”可迭代对象\n函数注解 函数声明中的各个参数可以在 : 之后增加注解表达式。如果参数有默认值，注解放在参数名和 = 号之间。如果想注解返回值，在 ) 和函数声明末尾的 : 之间添加 -\u0026gt; 和一个表达式。 那个表达式可以是任何类型。\n函数装饰器和闭包 函数装饰器用于在源码中**“标记”**函数，以某种方式增强函数的行为。\n装饰器基础 装饰器是可调用的对象，其参数是另一个函数。装饰器可能会处理被装饰的函数，然后把它返回，或者将其替换成另一个函数或可调用对象。\n特性1，能把被装饰的函数替换成其他函数。 特性2，装饰器在加载模块时立即执行。（被装饰的函数定义之后立即运行） 闭包 闭包指延伸了作用域的函数，能访问定义体之外定义的非全局变量。闭包是一种函数，它会保留定义函数时存在的自由变量的绑定，这样调用函数时， 虽然定义作用域不可用了，但是仍能使用那些绑定。\naverager 的闭包延伸到那个函数的作用域之外，包含自由变量 series 的绑定\n在 averager 函数中，series 是自由变量，指未在本地作用域中绑定的变量。\nnonlocal 声明：它的作用是把变量标记为自由变量， 即使在函数中为变量赋予新值了，也会变成自由变量。\n面向对象惯用法 对象引用、可变性和垃圾回收 💡 - 每个 Python 对象都有标识、类型和值。只有对象的值会不时变化。 - 变量保存的是引用，这一点对 Python 编程有很多实际的影响。 - 对象的引用数量归零后，对象会被立即销毁。 在**==**和is之间选择 == 运算符比较两个对象的值(对象中保存的数据)，而 is 比较对象的标识（即引用）。\na == b是语法糖，等同于a.eq(b)。继承自object的__eq__ 方法比较两个对象的 ID，结果与 is 一样。但是多数内置类型使用更有意义的方式覆盖了__eq__ 方法，会考虑对象属性的值。\n元组的相对不可变性 元组与多数 Python 集合(列表、字典、集，等等)一样，保存的是对象的引用。如果引用的元素是可变的，即便元组本身不可变，元素依然可变。\n深复制和浅复制 浅复制：即复制了最外层容器，副本中的元素是源容器中元素的引用 深复制：即副本不共享内部对象的引用 函数的参数作为引用时 **共享传参：**函数的各个形式参数获得实参中各个引用的副本。也就是说，函数内部的形参是实参的别名。因此，函数可能会修改作为参数传入的可变对象，但是无法修改那些对象的 标识(即不能把一个对象替换成另一个对象)。\n💡 默认值在定义函数时计算(通常在加载模块时)，因此默认值变成了函数对象的属性。因此，如果默认值是可变对象，而且修改了它的值，那么后续的函数调用都会受到影响。 del、垃圾回收和弱引用 垃圾回收使用的主要算法是引用计数，当引用计数归零时，对象立即就被销毁。 弱引用不会增加对象的引用数量。引用的目标对象称为所指对象(referent)。因此弱引用不会妨碍所指对象被当作垃圾回收。 符合Python风格的对象 ","permalink":"//localhost:1313/posts/fluent-python/","summary":"Fluent Python Owner: Huijie Liu Tags: Ongoing, Study Note\n数据结构 序列构成的数组 Python 标准库用 C 实现了丰富的序列类型，列举如下。\n容器序列 list、tuple 和 collections.deque 这些序列能存放不同类型的数据。 扁平序列 str、bytes、bytearray、memoryview 和 array.array，这类序列只能容纳一种类型。 容器序列存放的是它们所包含的任意类型的对象的引用，而扁平序列里存放的是值而不是 引用。换句话说，扁平序列其实是一段连续的内存空间。由此可见扁平序列其实更加紧 凑，但是它里面只能存放诸如字符、字节和数值这种基础类型。\n序列类型还能按照能否被修改来分类。\n可变序列 list、bytearray、array.array、collections.deque 和 memoryview。 不可变序列 tuple、str 和 bytes。 字典和集合 💡 **dict** 类型是 Python 语言的基石。模块的命名空间、 实例的属性和函数的关键字参数中都可以看到字典的身影。跟它有关的内置函数都在 __builtins__.__dict__ 模块中。 正是因为字典至关重要，Python 对它的实现做了高度优化，而散列表则是字典类型性能出 众的根本原因。集合(set)的实现其实也依赖于散列表。\n如果一个对象是可散列的，那么在这个对象的生命周期中，它的散列值是不变的，而且这个对象需要实现 hash() 方法。另外可散列对象还要有 eq() 方法，这样才能跟其他键做比较。如果两个可散列对象是相等的，那么它们的散列值一定是一样的。一般来讲用户自定义的类型的对象都是可散列的。\n文本和字节序列 把函数视作对象 💡 可以把函数赋值给变量、传给 其他函数、存储在数据结构中，以及访问函数的属性，供框架和一些工具使用。 一等函数 在 Python 中，函数是一等对象。编程语言理论家把“**一等对象”**定义为满足下述条件的程 序实体:\n在运行时创建 能赋值给变量或数据结构中的元素 能作为参数传给函数 能作为函数的返回结果 在 Python 中，整数、字符串和字典都是一等对象。","title":"Fluent Python"},{"content":"第一章 引言 一些前置概念：\n深度学习（deep learning）：让计算机从经验中学习，根据层次化的概念体系理解世界。深度学习通过其他较简单的表示来表达复杂表示，解决了表示学习中的核心问题。\n知识库（knowledge base）：将知识用形式化的语言进行硬编码，使用逻辑推理规则来自动地理解这些形式化语言的声明。\n机器学习（machine learning）：AI系统需要具备自己获取知识的能力，即从原始数据中提取模式的能力。\n表示学习（represnetation learning）：使用机器学习来发掘表示本身，而不仅仅把标识映射到输出。\n变差因素（factors of variation）：“因素”仅指代影响的不同来源，这些因素通常是不能被直接观测到的量，可以被看作数据的概念或者抽象。如，分析语音时，变差因素包括说话者的年龄、性别、口音和正在说的词语；分析汽车图像时，变差因素包括汽车的位置、颜色、太阳的角度和亮度。\n多层感知机（multilayer perceptron, MLP）：是一个将一组输入值映射到输出值的数学函数。该函数由许多较简单的函数复合而成。\n深度学习模型示意图 深度学习韦恩图 第二章 机器学习基础 学习算法 机器学习算法是一种能够从数据中学习的算法。“对于某类任务T和性能度量P，一个计算机程序被认为可以从经验E中学习是指，通过经验E改进后，它在任务T上由性能度量P衡量的性能有所提升。”\n任务T 通常机器学习任务定义为机器学习系统应该如何处理样本 （example）。样本是指我们从某些希望机器学习系统处理的对象或事件中收集到的已经量化的特征 （feature）的集合。常见的机器学习任务如下：分类、输入缺失分类、回归、转录、机器翻译、结构化输出、异常检测、合成和采样、缺失值填补、去噪、密度估计\n性能度量P “通常性能度量P是特定于系统执行的任务T而言的。”\n经验E “机器学习算法可以大致分类为无监督 （unsupervised）算法和监督 （supervised）算法。\n无监督学习算法 （unsupervised learning algorithm）训练含有很多特征的数据集，然后学习出这个数据集上有用的结构性质。在深度学习中，我们通常要学习生成数据集的整个概率分布，显式地，比如密度估计，或是隐式地，比如合成或去噪。还有一些其他类型的无监督学习任务，例如聚类，将数据集分成相似样本的集合。\n监督学习算法 （supervised learning algorithm）训练含有很多特征的数据集，不过数据集中的样本都有一个标签 （label）或目标 （target）。例如，Iris数据集注明了每个鸢尾花卉样本属于什么品种。监督学习算法通过研究Iris数据集，学习如何根据测量结果将样本划分为3个不同品种。”\n容量、过拟合和欠拟合 在先前未观测到的输入上表现良好的能力被称为泛化 （generalization）。欠拟合是指模型不能在训练集上获得足够低的误差，而过拟合是指训练误差和测试误差之间的差距太大。模型的容量是指其拟合各种函数的能力。容量低的模型可能很难拟合训练集。容量高的模型可能会过拟合。\n正则化 正则化是指修改学习算法，使其降低泛化误差而非训练误差。正则化是机器学习领域的中心问题之一，只有优化能够与其重要性相提并论。\n超参数和验证集 大多数机器学习算法都有超参数，可以设置来控制算法行为。超参数的值不是通过学习算法本身学习出来的。\n交叉验证 当数据集太小时，最常见的是k-折交叉验证过程，将数据集分成k个不重合的子集。测试误差可以估计为k次计算后的平均测试误差。在第i次测试时，数据的第i个子集用于测试集，其他的数据用于训练集。\n估计、偏差和方差 点估计 为一些感兴趣的量提供单个“最优”预测。点估计也可以指输入和目标变量之间关系的估计，我们将这种类型的点估计称为函数估计。\n偏差 估计的偏差被定义为\n方差和标准差 期望的变化程度是多少。\n监督学习算法 监督学习算法是给定一组输入x和输出y的训练集，学习如何关联输入和输出\n无监督学习算法 无监督算法只处理“特征”，不操作监督信号。监督和无监督算法之间的区别没有规范严格的定义，因为没有客观的判断来区分监督者提供的值是特征还是目标。通俗地说，无监督学习的大多数尝试是指从不需要人为注释的样本的分布中抽取信息。\n第三章 深度前馈网络 介绍 深度前馈网络（deep feedforward network），也叫作前馈神经网络（feedforward neural net-work）或者多层感知机（multilayer perceptron，MLP）。“这种模型被称为前向（feedforward）的，是因为信息流过x的函数，流经用于定义f的中间计算过程，最终到达输出y。在模型的输出和模型本身之间没有反馈（feedback）连接。当前馈神经网络被扩展成包含反馈连接时，它们被称为循环神经网络。\n前馈神经网络用许多不同函数复合在一起来表示。该模型与一个有向无环图相关联，而图描述了函数是如何复合在一起的。多个函数连接在一个链上称为链式结构，这些链式结构是神经网络中最常用的结构。链的全长被称为深度。最后一层被称为输出层。\n在神经网络训练过程中，训练数据直接指明了输出层在每一点x上必须做什么，但是训练数据并没有说每个单独的层应该做什么，所以这些层被称为隐藏层。\n基于梯度的学习 在于神经网络的非线性导致大多数我们感兴趣的代价函数都变得非凸。这意味着神经网络的训练通常使用迭代的、基于梯度的优化，仅仅使得代价函数达到一个非常小的值。\n代价函数 神经网络的代价函数或多或少是和其他的参数模型（例如线性模型的代价函数）相同的。\n输出单元 代价函数的选择与输出单元的选择紧密相关。任何可用作输出的神经网络单元，也可以被用作隐藏单元。\n隐藏单元 架构设计 更深层的网络通常能够对每一层使用更少的单元数和更少的参数，并且经常容易泛化到测试集，但是通常也更难以优化。\n万能近似定理表明，一个前馈神经网络如果具有线性输出层和至少一层具有任何一种“挤压”性质的激活函数（例如logistic sigmoid激活函数）的隐藏层，只要给予网络足够数量的隐藏单元，它可以以任意的精度来近似任何从一个有限维空间到另一个有限维空间的Borel可测函数。\n反向传播和其他的微分算法 第四章 正则化 第五章 优化 第六章 卷积网络 第七章 循环网络 第八章 实践 ","permalink":"//localhost:1313/posts/deep-learning/","summary":"第一章 引言 一些前置概念：\n深度学习（deep learning）：让计算机从经验中学习，根据层次化的概念体系理解世界。深度学习通过其他较简单的表示来表达复杂表示，解决了表示学习中的核心问题。\n知识库（knowledge base）：将知识用形式化的语言进行硬编码，使用逻辑推理规则来自动地理解这些形式化语言的声明。\n机器学习（machine learning）：AI系统需要具备自己获取知识的能力，即从原始数据中提取模式的能力。\n表示学习（represnetation learning）：使用机器学习来发掘表示本身，而不仅仅把标识映射到输出。\n变差因素（factors of variation）：“因素”仅指代影响的不同来源，这些因素通常是不能被直接观测到的量，可以被看作数据的概念或者抽象。如，分析语音时，变差因素包括说话者的年龄、性别、口音和正在说的词语；分析汽车图像时，变差因素包括汽车的位置、颜色、太阳的角度和亮度。\n多层感知机（multilayer perceptron, MLP）：是一个将一组输入值映射到输出值的数学函数。该函数由许多较简单的函数复合而成。\n深度学习模型示意图 深度学习韦恩图 第二章 机器学习基础 学习算法 机器学习算法是一种能够从数据中学习的算法。“对于某类任务T和性能度量P，一个计算机程序被认为可以从经验E中学习是指，通过经验E改进后，它在任务T上由性能度量P衡量的性能有所提升。”\n任务T 通常机器学习任务定义为机器学习系统应该如何处理样本 （example）。样本是指我们从某些希望机器学习系统处理的对象或事件中收集到的已经量化的特征 （feature）的集合。常见的机器学习任务如下：分类、输入缺失分类、回归、转录、机器翻译、结构化输出、异常检测、合成和采样、缺失值填补、去噪、密度估计\n性能度量P “通常性能度量P是特定于系统执行的任务T而言的。”\n经验E “机器学习算法可以大致分类为无监督 （unsupervised）算法和监督 （supervised）算法。\n无监督学习算法 （unsupervised learning algorithm）训练含有很多特征的数据集，然后学习出这个数据集上有用的结构性质。在深度学习中，我们通常要学习生成数据集的整个概率分布，显式地，比如密度估计，或是隐式地，比如合成或去噪。还有一些其他类型的无监督学习任务，例如聚类，将数据集分成相似样本的集合。\n监督学习算法 （supervised learning algorithm）训练含有很多特征的数据集，不过数据集中的样本都有一个标签 （label）或目标 （target）。例如，Iris数据集注明了每个鸢尾花卉样本属于什么品种。监督学习算法通过研究Iris数据集，学习如何根据测量结果将样本划分为3个不同品种。”\n容量、过拟合和欠拟合 在先前未观测到的输入上表现良好的能力被称为泛化 （generalization）。欠拟合是指模型不能在训练集上获得足够低的误差，而过拟合是指训练误差和测试误差之间的差距太大。模型的容量是指其拟合各种函数的能力。容量低的模型可能很难拟合训练集。容量高的模型可能会过拟合。\n正则化 正则化是指修改学习算法，使其降低泛化误差而非训练误差。正则化是机器学习领域的中心问题之一，只有优化能够与其重要性相提并论。\n超参数和验证集 大多数机器学习算法都有超参数，可以设置来控制算法行为。超参数的值不是通过学习算法本身学习出来的。\n交叉验证 当数据集太小时，最常见的是k-折交叉验证过程，将数据集分成k个不重合的子集。测试误差可以估计为k次计算后的平均测试误差。在第i次测试时，数据的第i个子集用于测试集，其他的数据用于训练集。\n估计、偏差和方差 点估计 为一些感兴趣的量提供单个“最优”预测。点估计也可以指输入和目标变量之间关系的估计，我们将这种类型的点估计称为函数估计。\n偏差 估计的偏差被定义为\n方差和标准差 期望的变化程度是多少。\n监督学习算法 监督学习算法是给定一组输入x和输出y的训练集，学习如何关联输入和输出\n无监督学习算法 无监督算法只处理“特征”，不操作监督信号。监督和无监督算法之间的区别没有规范严格的定义，因为没有客观的判断来区分监督者提供的值是特征还是目标。通俗地说，无监督学习的大多数尝试是指从不需要人为注释的样本的分布中抽取信息。\n第三章 深度前馈网络 介绍 深度前馈网络（deep feedforward network），也叫作前馈神经网络（feedforward neural net-work）或者多层感知机（multilayer perceptron，MLP）。“这种模型被称为前向（feedforward）的，是因为信息流过x的函数，流经用于定义f的中间计算过程，最终到达输出y。在模型的输出和模型本身之间没有反馈（feedback）连接。当前馈神经网络被扩展成包含反馈连接时，它们被称为循环神经网络。","title":"Deep Learning"}]