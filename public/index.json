[{"content":" 原文链接\nQ1: how to learn image representations? Overview 改进 CLIP 数据层面：Data scaling up 模型层面：Model design image side FLIP（Scaling CLIP training via masking）：是一种改进的训练方法，用于提高 CLIP模型的训练效率。FLIP 的核心思想是在训练过程中随机遮挡图像的部分区域，只对可见的区域进行编码。\nScaling language-image pre-training via masking, CVPR 2023\nlanguage side K-Lite: 将外部知识融入到对比学习预训练中，在 K-Lite 中，实体的维基百科定义（knowledge）可以与原始的图像替代文本（alt-text）一起自然地用于对比预训练。\nK-lite: Learning transferable visual models with external knowledge, NeurIPS 2022\nimproved interpretability STAIR（Learning Sparse Text and Image Representation in Grounded Tokens）： 将图像和文本映射到高维稀疏嵌入空间； 每个维度的值是一个非负标量，表示与该维度对应的词或标记的权重； 提供了更好的性能和更清晰地识别图像和文本之间的对应关系； STAIR: Learning Sparse Text and Image Representation in Grounded Tokens, 2023\nmore modalities ImageBind（One embedding space to bind them all）：将不同模态（在这篇论文中有7种模态）链接到一个共同空间的方法。 一个共同的嵌入空间。 使用冻结的预训练 CLIP。 学习其他模态编码器：对于每个非图像和文本的模态，ImageBind 学习一个编码器，将该模态的数据映射到 CLIP 的嵌入空间中。 目标函数：Objective function fine-grained supervision（细粒度监督） FILIP：通过细粒度监督来改进视觉-语言预训练的方法。即单词-图像块（patch）对齐。 双编码器结构：FILIP 仍然使用双编码器结构，即分别对图像和文本进行编码，而不是使用融合编码器。 细粒度监督：FILIP 的核心在于细粒度的监督。它首先计算单词和图像块之间的相似性，然后通过最大池化（max pooling）聚合这个相似性矩阵来计算损失。这种方法允许模型学习更细粒度的图像-文本对齐。 学习单词-图像块对齐：通过这种细粒度的相似性计算和损失函数，FILIP 能够学习单词和图像块之间的对齐关系。这种对齐对于可视化非常有用，因为它提供了图像和文本之间更明确的关联。 FILIP: Fine-grained Interactive Language-Image Pre-Training, ICLR 2022\nadding a generative branch Coca：通过在预训练阶段同时利用图像-文本对和图像-标签对来学习图像和文本的表征。并增加了一个生成分支，以提升模型性能并赋予其新的能力，如图像描述和视觉问答。 对比学习：CoCa 使用对比学习机制来学习图像和文本之间的对应关系，通过最大化相关图像-文本对的相似度，同时最小化不相关对的相似度。 混合数据预训练：CoCa 利用混合的图像-文本对和图像-标签对进行预训练。这种混合使用使模型能够同时学习丰富的视觉概念和复杂的跨模态关系。 生成分支：CoCa 在传统的对比学习框架上增加了一个生成分支。这个分支可以生成文本描述，从而增强模型的性能，并使模型能够执行图像描述和视觉问答等任务。 学习从零开始的图像编码器：Coca完全从零开始训练，以更深层次地理解视觉内容。 Coca: Contrastive captioners are image-text foundation models, 2022\nCLIP + 其他学习方法 CLIP + Supervised Learning Noisy label + text supervision（噪声标签+文本监督）\nUniCL ：它提供了一种原则性的方法来同时使用图像-标签和图像-文本数据。它是一种统一的对比学习（Unified Contrastive Learning）框架，旨在优化图像、文本和标签在同一空间内的表征。 LiT: Locking the image encoder：使用预训练好的image encoder并将它冻结，并添加文本塔实现开放词汇表。使text model学会从image encoder的结果中读取出好的表示。 MOFI：从带有噪声的实体标注图像中学习图像表示的方法。它结合了监督学习和对比学习，以提高模型在多任务环境中的性能。 Unified contrastive learning in image-text-label space, CVPR 2022\nLit: Zero-shot transfer with locked-image text tuning, CVPR 2022\nMOFI: Learning Image Representations from Noisy Entity Annotated Images, 2023\nCLIP + Image-Only (Non-) Contrastive Learning SimCLR：对于给定的图像，应用两种不同的数据增强方法，生成两个变体。这两个变体被视为正样本对，即它们代表同一图像的不同视角，并进行对比训练。 DeCLIP： 自监督学习： 图像模态：使用类似 SimCLR 的方法，通过双重数据增强和对比学习来学习图像的特征表示。 文本模态：使用掩码语言模型（MLM）的方式来学习文本的特征表示。 多视角监督（Multi-view supervision）：利用来自不同模态（如图像和文本）的信息作为互补的视角，通过对齐这些不同视角的表示来增强学习。 最近邻监督（Nearest-neighbor supervision）：在特征空间中，通过考虑样本的最近邻来引入额外的监督信号，从而促进模型学习更加鲁棒和区分性的特征。 SLIP：SLIP 的核心思想是将 SimCLR和 CLIP相结合进行模型训练。 xCLIP： xCLIP = CLIP + nCLIP，是对 CLIP 的一个扩展，它利用图像自监督学习的技术来实现非对比学习，通过正则化和高维投影来确保学到的表示具有足够的区分度和鲁棒性。 引入了锐度（sharpness）和平滑性（smoothness）正则化。锐度正则化鼓励模型学习到尖锐的、区分度高的特征，而平滑性正则化则确保模型不会对数据的微小变化过度敏感。 A Simple Framework for Contrastive Learning of Visual Representations, ICML 2020\nSupervision exists everywhere: A data efficient contrastive language-image pre-training paradigm, ICLR 2022\nSlip: Self-supervision meets language-image pretraining, ECCV 2022\nNon-Contrastive Learning Meets Language-Image Pre-Training, CVPR 2023\nImage-Only (Non-) Contrastive Learning + Masked Image Modeling BEiT：将自然语言处理中的预训练技术引入到图像领域，并通过视觉标记的概念建立起图像和文本之间的联系。 图像分词器（Image Tokenizer）：在预训练之前，首先使用 VQ-VAE或 GAN等方法学习一个“图像分词器”。将图像分割成一系列离散的视觉标记，类似于 DALL-E 和 Parti 等图像生成模型中使用的方法。 随机遮蔽与预测：在预训练阶段，随机遮蔽图像的一些区域（图像块），然后训练 BEiT 模型去预测这些被遮蔽的视觉标记。 知识蒸馏：这个过程可以理解为图像分词器和 BEiT 编码器之间的知识蒸馏，但后者只能看到图像的一部分。BEiT 编码器通过学习重建遮蔽的视觉标记，从而学习到图像的丰富表示。 MAE：使用像素值作为目标来训练模型。 大规模遮蔽：在预训练阶段，随机遮蔽图像的大部分区域（例如 75%），只留下一小部分可见区域。 编码器和遮蔽标记：将编码器应用于可见的图像块，以提取特征。在编码器之后引入遮蔽标记。 像素级重建：模型的任务是预测被遮蔽区域的像素值，从而重建整个图像。 适用于目标检测和分割：MAE 预训练对于目标检测和分割等任务特别有帮助，因为它强化了模型对图像局部细节和整体结构的理解。 MIM很适合模型微调，但不能学习全局图像表示，也不适用大规模数据缩放。\nBEiT: BERT Pre-Training of Image Transformers, ICLR 2022\nMasked Autoencoders Are Scalable Vision Learners, CVPR 2022\nCLIP + Masked Image Modeling （Shallow interaction） CLIP和 MIM是两种不同的自监督学习方法，它们各自专注于不同方面的特征学习。\nMVP：使用 CLIP 的图像特征作为 MIM 训练的目标，可以捕获在MIM训练中缺失的语义，这种做法能够结合两种方法的优势，提升模型在捕捉图像语义信息方面的能力。 EVA：推广了这一方法 Masked Autoencoding Does Not Help Natural Language Supervision at Scale：MAE对大规模的自然语言监督没有帮助。 BEiT-3：结合了 BERT和 BEiT的思想，进行多模态数据的遮蔽建模。 多模态变换器（Multiway Transformer）：BEiT-3 使用一个多路变换器来处理图像/文本和图像-文本数据。这种架构允许模型同时处理并整合来自不同模态的信息。\n遮蔽数据建模：与单一模态的 MIM 类似，BEiT-3 对图像和文本数据进行遮蔽处理，并训练模型去预测被遮蔽的部分。这种方式促使模型学习到深层次的、跨模态的表示。\n共享自注意力层：BEiT-3 设计了共享的自注意力层，这些层可以处理来自不同模态的信息。这种共享机制有助于提高模型的参数效率和泛化能力。\n模态专家前馈网络（FFN Modality Experts）：模型包含三个前馈网络（FFN）模态专家，分别专注于处理图像、文本和图像-文本数据。这种设计使得模型能够针对不同模态的数据学习特定的特征。\nMVP: Multimodality-guided Visual Pre-training, ECCV 2022\nEVA: Exploring the Limits of Masked Visual Representation Learning at Scale, CVPR 2023\nMasked Autoencoding Does Not Help Natural Language Supervision at Scale, CVPR 2023\nImage as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks\n主干网络（Backbones） 总结 三个高层次的原则 可扩展性（Scaling）：一个好的算法应该简单，但也能够很好地扩展。这意味着算法应该能够处理大规模的数据集和模型，同时保持良好的性能。 对比（Contrasting）：从 SimCLR 到 CLIP，对比学习在自监督学习中扮演着重要角色。通过比较正负样本对，模型学习到区分不同数据点的能力。 遮蔽（Masking）：从 BERT 到 BEiT，遮蔽技术被广泛应用于自监督学习中。通过预测被遮蔽部分的内容，模型能够学习到数据的内在结构和特征。 展望 进一步扩展规模：\n数据规模和模型规模的扩展仍是一个挑战。需要探索更有效的方法来处理和学习超大规模的数据集，以及设计更大更强大的模型架构。 新的模型训练范式：\n寻找超越 CLIP 和 MIM 的简单且可扩展的算法。这可能涉及到新的学习机制、训练策略或模型架构。 统一的图像-/区域-/像素级预训练：\n开发能够在不同粒度级别上对图像进行全面理解的模型。这需要模型能够同时捕捉到全局信息和局部细节。 具有更灵活、可提示（promptable）接口的视觉模型：\n将自然语言处理中的概念（如上下文学习、思维链、提示、新兴属性等）引入到计算机视觉中。探索如何使视觉模型能够通过提示进行灵活的交互和学习。 使用更创新的数据训练视觉主干网络：\n探索新的数据来源和类型，以解锁模型的新能力，类似于 GPT-4 展示的能力。例如，训练模型阅读整个扫描的论文，然后用几个要点来总结论文内容。 Q2: how to extend vision models with more flexible, promptable interfaces? 计算机视觉领域独有的挑战 模型 输入格式多种多样：图片，视频，多模态（附带文本/语音） 不同粒度的任务：图片级，区域级，像素级 不同类型的输出：空间输出，文本输出 数据 如何解决 Bridge Vision with Language 学习原始视觉信号与丰富语义之间的映射，并可以对各种开放词汇视觉识别任务提供动力\nGroupViT：通过从头开始学习图像-文本对来学习对语义相似的区域进行分组 使用分组块进行自下而上的分组 自上而下的图像-文本监督以实现视觉语义对齐 MaskCLIP：从CLIP中提取自由的密集标签 将注意力池更改为新的适应策略 使用CLIP作为教师模型的伪标签掩码 OpenSeg：弱监督学习，通过强制文本特征和掩码池特征之间的细粒度对齐。 从图像-文本对和局部描述中学习。 使用预训练的掩码建议网络。 MaskCLIP (UCSD)：使用CLIP作为初始化的COCO全视分割的监督训练 掩码建议网络训练 CLIP模型自适应 总结 CLIP作为基础对开放词汇训练有很大帮助 将弱注释与黄金注释结合起来以获得更好的性能 Unified multi-task modeling 希望开发一个统一的视觉模型，该模型可以在许多视觉任务中表现良好。\n两种统一化\nOutputs Unification 概述 以一致的格式表示不同输出（一个输出里包含多个任务的结果） UniTab and Pix2Seqv2 统一词表： 将文本和坐标都进行标记化（tokenization），并放入同一个词表中。 任务前缀： 需要一个任务前缀来确定模型正在处理的任务 Unified-IO：加入了VQVAE 预训练 VQVAE： 先单独对 VQVAE 进行预训练，让它学习有效地表示和离散化不同类型的视觉信息。 序列到序列的联合训练： 在预训练的 VQVAE 之上，以序列到序列（Sequence-to-Sequence）的方式对整个 Unified-IO 模型进行联合训练。这样做是为了让模型学习如何处理不同模态的输入，并生成符合不同任务要求的序列形式输出。 总结 优点： 这个方式可以让一个模型通过自然语言的转换来适应各种视觉任务。 局限性： 仍然需要有任务特定的步骤来把大语言模型的输出转化成可用的结构化数据。 中间过程涉及自然语言，因此模型内部不同任务的交互关系可能会更难以解释。 相比直接输出结构化数据的模型，VisionLLM 在整合不同任务、提升整体性能方面可能存在局限性。 Functionality Unification 概述 知识迁移： 一个模型在特定任务上学习到的能力，可以较容易地迁移到使用相似输出类型的其他任务上。 模型简化： 我们可以设计更具有通用性的模型架构，通过输出层的适配来应对不同的视觉任务。 多任务学习： 既然任务之间存在关联，就有机会设计联合学习方案，让模型同时在多个任务上训练，以相互促进，提升整体性能。 UniPerceiver-v2 X-Decoder：允许图像级和像素级的监督信号相互作用。 LLM-like promptable interface 概述：一个通用的视觉模型应该具有相同的上下文学习能力，在不改变模型参数的情况下将输出与各种用户意图对齐。 上下文记忆 （Context Memory）： 模型需要能存储和处理之前交互轮次中的信息。这可能是通过一个外部记忆模块，或者大规模参数模型本身的记忆能力来实现。 提示构建（Prompt Construction）： 系统能够根据：1) 用户的多轮意图输入； 2) 存储的上下文信息来自动构建模型的提示。提示的内容可能包括任务描述、指示、以及之前的示例交互。 SAM SEEM: Segment Everything Everywhere all at Once Q3: how to do image generation? Overview 4大主题 研究总结 T2I模型总览 DF原理 交叉注意力机制：K和V代表键（Key）和值（Value），它们是从文本流τ(y)投影来的，而Q是从视觉流投影来的，都具有相同的隐藏维度d。因此，Q和K之间的softmax运算产生了一个大小为(hw×d)·(N×d)转置= hw×N的注意力图M。这个交叉注意力图M表示图像和文本之间的细粒度交互，对于文本中的每一个词N，在所有空间位置hw上都有交互。然后注意力图M与V进行点积运算，以产生一个下采样/上采样块的输出。\nSpatial Controllable Generation 区域绑定的文本描述：将传统T2I模型中的图像级文本描述扩展到区域绑定的文本描述，使得开放式文本描述能够精确地操作特定的空间区域。\nReCo：其核心思想是扩展文本编码器E的文本词汇，并安排不同的标记以表示绑定的文本输入。该研究通过增加一组位置标记（例如，\u0026lt;687\u0026gt;、\u0026lt;204\u0026gt;、\u0026lt;999\u0026gt;、\u0026lt;833\u0026gt;），这些位置标记与文本标记无缝混合，并作为空间修饰符，指示接下来的文本仅在指定的空间区域操作。\nGLIGEN：采用了一种即插即用的方法，冻结原始T2I模型，并训练额外的门控自注意力层来学习新的定位技能。定位令牌携带两种类型的信息：需要在其中定位的文本词的语义表示和它们的空间配置。然后，通过新增加的门控自注意力层将这些定位令牌添加到预训练的T2I模型中，所有剩余的预训练参数都被冻结。\nReco: Region-controlled text-to-image generation.\nGligen: Open-set grounded text-to-image generation\n密集空间条件：这一类研究从边界框扩展到以2D数组形式表示的密集空间条件，如分割掩码、边缘图、深度图和关键点等。\nControlNet：向文本提示添加了额外的输入条件。这个额外的条件可以是Canny边缘图、霍夫线、HED边界、素描、人体姿势图、分割掩模、深度图像、法线图或线条图，每个条件都有其独特的模型副本。\nControlNet：Adding conditional control to text-to-image diffusion models.\n推理时指导：前两类工作需要对T2I模型进行微调以理解扩展的空间条件。第三类技术探讨了在不对模型进行微调的情况下实现空间控制的方法。\n核心思想与分类器指导（Classifier guidance）类似，即使用判别器损失来引导扩散过程。具体来说，就是在扩散过程的每一步，加入一个额外的项，这个项是由判别器计算出的目标检测损失与期望布局有关的梯度，乘以一个指导强度因子，这样可以在不额外训练模型的情况下实现空间控制。 Text-based Editing 文本到图像编辑（Text-to-image editing）是一种从给定图像和输入的文本描述中合成新图像的技术。可以是之前从文本到图像模型生成的图像，或者是自然图像。目标是保留大部分视觉内容，只修改特定组成部分。\n局部图像区域变化：经典的编辑场景之一是改变局部图像区域，例如移除、更换或在某个区域内添加对象。 扩展的空间编辑：语言输入描述了空间区域中期望的外观，语言也可以用作编辑指令告诉机器要做什么，例如“将图像中的对象A更改为对象B”。 综合编辑系统：不是扩展单一的文本到图像（T2I）模型进行编辑，编辑系统集成了不同的专业模块，如分割模型和大型语言模型。 Text Prompts Following 文本到图像（T2I）模型可能无法遵循文本提示的问题，尤其是当图像描述变得复杂时。例如，某些名词短语可能被遗漏，属性可能应用于错误的对象，生成的图像可能有错误的对象数量、关系、风格等。\n推理时操作（Inference-time manipulation）:\n在推理阶段，设计各种方法来重新分配视觉潜在表示或图像-文本交叉注意力，以确保文本提示中的所有名词短语都在生成的图像中得到体现。 StructureDiffusion：使用解析树来提取名词短语和文本提示的语言结构，然后强制模型“关注”所有提取的名词短语。这是通过修改交叉注意力机制来实现的，其中 O = M · V，M 是 softmax 交叉注意力图，V 是句子特征。$$O=\\frac1{k+1}\\Sigma_{i=0}^k(M\\cdot V_i)$$，其中 $$V_0$$ 是句子特征 ，$$V_i$$ 是解析树中的短语特征。这种方法确保视觉流在所有识别的名词短语上保持平衡的注意力，从而促进更准确的图像生成。\nAttend-and-Excite：提出了一种正则化损失函数 $$\\begin{aligned}\\ell=\\max_{n=1,\u0026hellip;,N_{\\mathrm{sub}}}(1-max\\left.G(M_t^n)\\right)\\end{aligned}$$，用于增强最被忽视的主题tokens的最大注意力。该正则化损失函数使用了一个高斯核 G 来平滑注意力地图，$$N_{sub}$$是主题tokens的数量。然后利用这个损失函数更新在推理时间的潜在表示 zt，更新公式为$$z_t^{\\prime}=z_t-\\alpha\\nabla_{z_t}\\ell$$，$$\\alpha$$是步长大小。\nTraining-free structured diffusion guidance for compositional text-to-image synthesis\nAttend-and-excite: Attention-based semantic guidance for text-to-image diffusion models.\n对齐调优（Alignment tuning）:\n学习一个额外的模型学习阶段，通常以图像-文本相似性作为奖励，使得调优后的模型能够更好地遵循文本提示。 DDPO：加入强化学习\nTraining diffusion models with reinforcement learning\nConcept Customization 直接扩展T2I模型以通过图像输入理解视觉概念。\n单一概念定制: 从单一概念定制开始，该过程涉及测试时微调，将视觉概念的多张图片编码成新的Token嵌入。\nTextual Inversion：T2I 模型处理不同狗品种的四个图像，随后学习新标记的嵌入，表示为 [V]。这个 [V] 标记可以用作文本标记来表示这个特定的狗。[V] 令牌可以与其他文本描述无缝集成。文本反转通过前缀调整来学习 [V] 令牌嵌入，即冻结所有 T2I 模型的参数并训练 [V] 令牌嵌入以生成输入图像。\nDreambooth：仅调整输入图像可能会导致对特定概念的 T2I 模型过度拟合的风险，为了解决这个问题，本文提出了特定于类的先验保留损失。这种方法的核心是使用预训练的 T2I 模型来生成与目标定制概念相同的类图像。然后，该模型在输入图像（使用 [V] 令牌）和模型生成的图像（没有 [V] 令牌）上联合微调。确保了模型能够在独特的“[V] 狗”和它最初训练的其他一般狗之间进行区分，同时保持其整体的T2I能力。\nAn image is worth one word: Personalizing text-to-image generation using textual inversion\nDreambooth: Fine tuning text-to-image diffusion models for subject-driven generation.\n多概念定制: 允许扩展文本到图像模型的Token词汇表，以包括多个概念Tokens，这使得多个概念能够在生成过程中相互作用以及与剩余的视觉场景交互。\nCustom Diffusion Multi-concept customization of text-to-image diffusion.\n个性化测试微调的简化: 由于测试时微调要求用户为每个新概念定制T2I模型，这可能会变得相当复杂。为简化使用流程，一些研究探索了无需测试时微调的定制方法，采用统一的微调阶段来扩展T2I模型，使其接受图像条件输入。这些模型将视觉概念的图像作为额外的输入条件，并根据文本描述生成包含视觉概念的图像。\nSuTI：训练单个模型来模拟微调的主题特定专家，并生成以文本和主题输入图像为条件的图像。 Subject-driven text-to-image generation via apprenticeship learning\n展望 Unified image and text inputs（统一图像文本输入） Tuning with alignment-focused loss and rewards（聚焦于对齐的损失和奖励） Closed-loop of multimodal content understanding and generation（多模态内容理解和生成的闭环） Q4: how to train multimodal LLM? Image-to-Text Generative Models 模型架构 预训练图像编码器与语言模型：这是多模态模型的基础。图像编码器（通常为基于 CNN 或 Transformer 的结构）学习提取图像的视觉特征，而语言模型（如 GPT 系列）负责建模文本序列的内在规律。 连接两个模态的可训练模块：为了融合视觉与语言信息，模型需要有专门的可训练模块。常见的有： Cross-Attentional Mechanisms： 跨模态注意力机制让图像特征与文本相互影响，赋予模型理解图文联系的能力。 Multimodal Fusion Modules： 多模态融合模块负责将来自不同模态的信息聚合，形成统一的表示。 训练目标 Cross-Attended Image-to-Text Generation：模型通过跨模态注意力，逐步生成与图像对应的文本描述。这是许多图像描述生成模型的核心目标。 Autoregressive loss on language output：自回归损失用于训练语言模型的生成能力。通过最小化预测的下一个词与真实词之间的差异，使模型学习生成流畅、自然的文本序列。 Large Multimodal Models LLaVA: Large Language-and-Vision Assistant 总结 Q5: how to chain vision experts with LLM? LLM + 各种工具\nEvolution of Modeling Paradigm New Paradigm MM-ReAct: Prompting ChatGPT for Multimodal Reasoning and Action\n","permalink":"/posts/recent-advances-in-vision-foundation-models.assets/","summary":"原文链接\nQ1: how to learn image representations? Overview 改进 CLIP 数据层面：Data scaling up 模型层面：Model design image side FLIP（Scaling CLIP training via masking）：是一种改进的训练方法，用于提高 CLIP模型的训练效率。FLIP 的核心思想是在训练过程中随机遮挡图像的部分区域，只对可见的区域进行编码。\nScaling language-image pre-training via masking, CVPR 2023\nlanguage side K-Lite: 将外部知识融入到对比学习预训练中，在 K-Lite 中，实体的维基百科定义（knowledge）可以与原始的图像替代文本（alt-text）一起自然地用于对比预训练。\nK-lite: Learning transferable visual models with external knowledge, NeurIPS 2022\nimproved interpretability STAIR（Learning Sparse Text and Image Representation in Grounded Tokens）： 将图像和文本映射到高维稀疏嵌入空间； 每个维度的值是一个非负标量，表示与该维度对应的词或标记的权重； 提供了更好的性能和更清晰地识别图像和文本之间的对应关系； STAIR: Learning Sparse Text and Image Representation in Grounded Tokens, 2023","title":"Recent Advances in Vision Foundation Models"},{"content":"正向代理 正向代理是客户端和服务器中间的服务器，为了从原始服务器取得内容，客户端向代理服务器发送一个请求并指定目标（原始服务器）， 然后代理服务器向原始服务器转发请求并将获得的内容返回给客户端。\n举个例子，比如正常情况下我没法办上youtube，但是我有个aws的机器，它不受GFW的限制，能够访问youtube，我也能正常访问那个aws的机器， 那么我通过发送请求给aws的机器，让他转发我的请求给youtube，然后把youtube返回的数据给我，我就能通过aws的机器作为跳板访问GFW， 那个aws的机器也就是代理服务器的角色，并且这种方式就是正向代理。\n总结一下，正向代理就是我想访问一台机器，但是被墙了访问不到，我需要一台机器作为跳板转发我的请求。\n反向代理 于正向代理不同，反向代理更多的是为了保护原始服务器。 对于客户端而言，反向代理中的代理服务器就是原始服务器，客户端并不需要知道有这个代理的角色存在， 因此客户端也不需要一些额外的设置，比如正向代理中制定代理服务器是谁。\n比如在原始服务器A上配置防火墙，使得只有服务器B能够访问A，并且通过B服务器转发A的数据实现于外界的通信。这样对于客户端，它只需要和B交互， 从而隐藏了服务器A，B服务器也就是反向代理服务器。由于有代理服务器的存在，对于后面的原始服务器来说，也就多了一层做负载均衡的服务器。\n透明代理 还有一种代理方式叫做透明代理，比如公司的机器不能上qq，这个就是透明代理，它在内网和外网之间捕捉用户的请求，过滤一部分请求。\nSSH端口转发 有一种很简单的方式就能做到代理功能，那就是SSH本身提供的端口转发功能。 要想理解清楚SSH端口转发，首先必须记住这样几个原则：\nSSH简单的理解就是2台机器之间安全的数据通道，它包括ssh的client和ssh的server2个角色，这样的一条通道也就是ssh隧道(ssh tunneling) SSH 端口转发自然需要 SSH 连接，而 SSH 连接是有方向的，从 SSH Client 到 SSH Server 我们的应用的请求也是有方向的，一般是客户端向服务器端发出请求 一旦这2个方向相同，我们称为ssh的本地转发(-L)，不同则为远端转发(-R) 命令一般是跑在ssh client的机器上的 本地转发 ssh本地转发命令为：\nssh -L \u0026lt;local port\u0026gt;:\u0026lt;remote host\u0026gt;:\u0026lt;remote port\u0026gt; \u0026lt;SSH hostname\u0026gt; 这条命令可以翻译成：从本地的端口发出请求，通过这台机器作为跳板转发请求到的端口。 是相对而言的，比如是127.0.0.1的话，就是本身。 所以一般如果是127.0.0.1的话，跳板机或者代理服务器就是目标服务器。\n举个例子：\nA是一台在我家的机器macbook air，它可以访问taobao，也就是服务器C B是一台在公司的机器imac，由于在公司的内网，所以在家的A访问不到B C是taobao的服务器，公司不让上taobao，所以服务器B访问不了C 现在要想在让B服务器能访问C的80端口，由于防火墙这条路本身是走不通的，但是由于B能访问A，A能访问C，所以能把A作为代理服务器实现这一要求。\n在服务器B和服务器A之间建立ssh隧道，在SSH端口转发中，由于服务器B能连接到服务器A，并且请求是从服务器B发出，所以B既是ssh的client，也是请求的客户端 所以此时应该在B上去运行ssh的本地转发命令: ssh -L 8080:HOST_C:80 HOST_A\n远端转发 ssh远端转发的命令为：\nssh -R \u0026lt;local port\u0026gt;:\u0026lt;remote host\u0026gt;:\u0026lt;remote port\u0026gt; \u0026lt;SSH hostname\u0026gt; 由于本身B是可以访问A的，但是A访问不到B，现在要想服务器A访问到B，也就是在家能连上公司的机器。\n服务器B能连上A，所以B应该是ssh的client，此时请求是由A发起的，所以A是请求客户端，方向不同，所以是远端转发。 因此在B上运行命令: ssh -R 2222:127.0.0.1:22 HOST_A ,这里127.0.0.1是因为通过A服务器转发的目的服务器就是A本身。 这样在A上的2222端口就映射到了B的22端口。\n动态转发 不管是本地转发还是远端转发，都需要一个具体的应用服务器的地址和端口号，要想访问其他机器的内容就得绑定很多条这样的转发命令， 通过动态转发就能省去这一个应用服务器的信息。\nssh -D \u0026lt;local port\u0026gt; \u0026lt;SSH Server\u0026gt; 当我们在一个不安全的 WiFi 环境下上网，用 SSH 动态转发来保护我们的网页浏览等信息无疑是十分必要的。 比如在本机运行： sh -D 7001 \u0026lt;SSH Server\u0026gt; 这样就相当于通过创建了一个SOCKS代理。\n我们可以直接使用localhost:7001 来作为正常的 SOCKS 代理来使用，直接在浏览器上设置即可。 在 SSH Client 端无法访问的网站现在也都可以正常浏览。 而这里需要值得注意的是，此时 SSH 所包护的范围只包括从浏览器端（SSH Client 端）到 SSH Server 端的连接，并不包含从 SSH Server 端 到目标网站的连接。 如果后半截连接的安全不能得到充分的保证的话，这种方式仍不是合适的解决方案。\n这个时候还可以在本机将SOCKS代理转成HTTP代理。 比如在本地安装polipo，修改polipo.conf文件，把SOCKS代理填上127.0.0.1:7001，然后 export http_proxy=\u0026quot;127.0.0.1:8123\u0026quot; \u0026amp;\u0026amp; export https_proxy=\u0026quot;127.0.0.1:8123\u0026quot; 就在本地的8123端口起了一个http代理。\n","permalink":"/posts/proxy/","summary":"正向代理 正向代理是客户端和服务器中间的服务器，为了从原始服务器取得内容，客户端向代理服务器发送一个请求并指定目标（原始服务器）， 然后代理服务器向原始服务器转发请求并将获得的内容返回给客户端。\n举个例子，比如正常情况下我没法办上youtube，但是我有个aws的机器，它不受GFW的限制，能够访问youtube，我也能正常访问那个aws的机器， 那么我通过发送请求给aws的机器，让他转发我的请求给youtube，然后把youtube返回的数据给我，我就能通过aws的机器作为跳板访问GFW， 那个aws的机器也就是代理服务器的角色，并且这种方式就是正向代理。\n总结一下，正向代理就是我想访问一台机器，但是被墙了访问不到，我需要一台机器作为跳板转发我的请求。\n反向代理 于正向代理不同，反向代理更多的是为了保护原始服务器。 对于客户端而言，反向代理中的代理服务器就是原始服务器，客户端并不需要知道有这个代理的角色存在， 因此客户端也不需要一些额外的设置，比如正向代理中制定代理服务器是谁。\n比如在原始服务器A上配置防火墙，使得只有服务器B能够访问A，并且通过B服务器转发A的数据实现于外界的通信。这样对于客户端，它只需要和B交互， 从而隐藏了服务器A，B服务器也就是反向代理服务器。由于有代理服务器的存在，对于后面的原始服务器来说，也就多了一层做负载均衡的服务器。\n透明代理 还有一种代理方式叫做透明代理，比如公司的机器不能上qq，这个就是透明代理，它在内网和外网之间捕捉用户的请求，过滤一部分请求。\nSSH端口转发 有一种很简单的方式就能做到代理功能，那就是SSH本身提供的端口转发功能。 要想理解清楚SSH端口转发，首先必须记住这样几个原则：\nSSH简单的理解就是2台机器之间安全的数据通道，它包括ssh的client和ssh的server2个角色，这样的一条通道也就是ssh隧道(ssh tunneling) SSH 端口转发自然需要 SSH 连接，而 SSH 连接是有方向的，从 SSH Client 到 SSH Server 我们的应用的请求也是有方向的，一般是客户端向服务器端发出请求 一旦这2个方向相同，我们称为ssh的本地转发(-L)，不同则为远端转发(-R) 命令一般是跑在ssh client的机器上的 本地转发 ssh本地转发命令为：\nssh -L \u0026lt;local port\u0026gt;:\u0026lt;remote host\u0026gt;:\u0026lt;remote port\u0026gt; \u0026lt;SSH hostname\u0026gt; 这条命令可以翻译成：从本地的端口发出请求，通过这台机器作为跳板转发请求到的端口。 是相对而言的，比如是127.0.0.1的话，就是本身。 所以一般如果是127.0.0.1的话，跳板机或者代理服务器就是目标服务器。\n举个例子：\nA是一台在我家的机器macbook air，它可以访问taobao，也就是服务器C B是一台在公司的机器imac，由于在公司的内网，所以在家的A访问不到B C是taobao的服务器，公司不让上taobao，所以服务器B访问不了C 现在要想在让B服务器能访问C的80端口，由于防火墙这条路本身是走不通的，但是由于B能访问A，A能访问C，所以能把A作为代理服务器实现这一要求。\n在服务器B和服务器A之间建立ssh隧道，在SSH端口转发中，由于服务器B能连接到服务器A，并且请求是从服务器B发出，所以B既是ssh的client，也是请求的客户端 所以此时应该在B上去运行ssh的本地转发命令: ssh -L 8080:HOST_C:80 HOST_A\n远端转发 ssh远端转发的命令为：\nssh -R \u0026lt;local port\u0026gt;:\u0026lt;remote host\u0026gt;:\u0026lt;remote port\u0026gt; \u0026lt;SSH hostname\u0026gt; 由于本身B是可以访问A的，但是A访问不到B，现在要想服务器A访问到B，也就是在家能连上公司的机器。","title":"About proxy"},{"content":"Fluent Python Owner: Huijie Liu Tags: Ongoing, Study Note\n数据结构 序列构成的数组 Python 标准库用 C 实现了丰富的序列类型，列举如下。\n容器序列 list、tuple 和 collections.deque 这些序列能存放不同类型的数据。 扁平序列 str、bytes、bytearray、memoryview 和 array.array，这类序列只能容纳一种类型。 容器序列存放的是它们所包含的任意类型的对象的引用，而扁平序列里存放的是值而不是 引用。换句话说，扁平序列其实是一段连续的内存空间。由此可见扁平序列其实更加紧 凑，但是它里面只能存放诸如字符、字节和数值这种基础类型。\n序列类型还能按照能否被修改来分类。\n可变序列 list、bytearray、array.array、collections.deque 和 memoryview。 不可变序列 tuple、str 和 bytes。 字典和集合 💡 **dict** 类型是 Python 语言的基石。模块的命名空间、 实例的属性和函数的关键字参数中都可以看到字典的身影。跟它有关的内置函数都在 __builtins__.__dict__ 模块中。 正是因为字典至关重要，Python 对它的实现做了高度优化，而散列表则是字典类型性能出 众的根本原因。集合(set)的实现其实也依赖于散列表。\n如果一个对象是可散列的，那么在这个对象的生命周期中，它的散列值是不变的，而且这个对象需要实现 hash() 方法。另外可散列对象还要有 eq() 方法，这样才能跟其他键做比较。如果两个可散列对象是相等的，那么它们的散列值一定是一样的。一般来讲用户自定义的类型的对象都是可散列的。\n文本和字节序列 把函数视作对象 💡 可以把函数赋值给变量、传给 其他函数、存储在数据结构中，以及访问函数的属性，供框架和一些工具使用。 一等函数 在 Python 中，函数是一等对象。编程语言理论家把“**一等对象”**定义为满足下述条件的程 序实体:\n在运行时创建 能赋值给变量或数据结构中的元素 能作为参数传给函数 能作为函数的返回结果 在 Python 中，整数、字符串和字典都是一等对象。\n高阶函数 接受函数为参数，或者把函数作为结果返回的函数是高阶函数。函数式语言通常会提供 map、filter 和 reduce 三个高阶函数。\n函数内省 除了 doc，函数对象还有很多属性。使用 dir 函数可以探知所有属性:\n调用函数时使用 * 和 **“展开”可迭代对象\n函数注解 函数声明中的各个参数可以在 : 之后增加注解表达式。如果参数有默认值，注解放在参数名和 = 号之间。如果想注解返回值，在 ) 和函数声明末尾的 : 之间添加 -\u0026gt; 和一个表达式。 那个表达式可以是任何类型。\n函数装饰器和闭包 函数装饰器用于在源码中**“标记”**函数，以某种方式增强函数的行为。\n装饰器基础 装饰器是可调用的对象，其参数是另一个函数。装饰器可能会处理被装饰的函数，然后把它返回，或者将其替换成另一个函数或可调用对象。\n特性1，能把被装饰的函数替换成其他函数。 特性2，装饰器在加载模块时立即执行。（被装饰的函数定义之后立即运行） 闭包 闭包指延伸了作用域的函数，能访问定义体之外定义的非全局变量。闭包是一种函数，它会保留定义函数时存在的自由变量的绑定，这样调用函数时， 虽然定义作用域不可用了，但是仍能使用那些绑定。\naverager 的闭包延伸到那个函数的作用域之外，包含自由变量 series 的绑定\n在 averager 函数中，series 是自由变量，指未在本地作用域中绑定的变量。\nnonlocal 声明：它的作用是把变量标记为自由变量， 即使在函数中为变量赋予新值了，也会变成自由变量。\n面向对象惯用法 对象引用、可变性和垃圾回收 💡 - 每个 Python 对象都有标识、类型和值。只有对象的值会不时变化。 - 变量保存的是引用，这一点对 Python 编程有很多实际的影响。 - 对象的引用数量归零后，对象会被立即销毁。 在**==**和is之间选择 == 运算符比较两个对象的值(对象中保存的数据)，而 is 比较对象的标识（即引用）。\na == b是语法糖，等同于a.eq(b)。继承自object的__eq__ 方法比较两个对象的 ID，结果与 is 一样。但是多数内置类型使用更有意义的方式覆盖了__eq__ 方法，会考虑对象属性的值。\n元组的相对不可变性 元组与多数 Python 集合(列表、字典、集，等等)一样，保存的是对象的引用。如果引用的元素是可变的，即便元组本身不可变，元素依然可变。\n深复制和浅复制 浅复制：即复制了最外层容器，副本中的元素是源容器中元素的引用 深复制：即副本不共享内部对象的引用 函数的参数作为引用时 **共享传参：**函数的各个形式参数获得实参中各个引用的副本。也就是说，函数内部的形参是实参的别名。因此，函数可能会修改作为参数传入的可变对象，但是无法修改那些对象的 标识(即不能把一个对象替换成另一个对象)。\n💡 默认值在定义函数时计算(通常在加载模块时)，因此默认值变成了函数对象的属性。因此，如果默认值是可变对象，而且修改了它的值，那么后续的函数调用都会受到影响。 del、垃圾回收和弱引用 垃圾回收使用的主要算法是引用计数，当引用计数归零时，对象立即就被销毁。 弱引用不会增加对象的引用数量。引用的目标对象称为所指对象(referent)。因此弱引用不会妨碍所指对象被当作垃圾回收。 符合Python风格的对象 ","permalink":"/posts/fluent-python/","summary":"Fluent Python Owner: Huijie Liu Tags: Ongoing, Study Note\n数据结构 序列构成的数组 Python 标准库用 C 实现了丰富的序列类型，列举如下。\n容器序列 list、tuple 和 collections.deque 这些序列能存放不同类型的数据。 扁平序列 str、bytes、bytearray、memoryview 和 array.array，这类序列只能容纳一种类型。 容器序列存放的是它们所包含的任意类型的对象的引用，而扁平序列里存放的是值而不是 引用。换句话说，扁平序列其实是一段连续的内存空间。由此可见扁平序列其实更加紧 凑，但是它里面只能存放诸如字符、字节和数值这种基础类型。\n序列类型还能按照能否被修改来分类。\n可变序列 list、bytearray、array.array、collections.deque 和 memoryview。 不可变序列 tuple、str 和 bytes。 字典和集合 💡 **dict** 类型是 Python 语言的基石。模块的命名空间、 实例的属性和函数的关键字参数中都可以看到字典的身影。跟它有关的内置函数都在 __builtins__.__dict__ 模块中。 正是因为字典至关重要，Python 对它的实现做了高度优化，而散列表则是字典类型性能出 众的根本原因。集合(set)的实现其实也依赖于散列表。\n如果一个对象是可散列的，那么在这个对象的生命周期中，它的散列值是不变的，而且这个对象需要实现 hash() 方法。另外可散列对象还要有 eq() 方法，这样才能跟其他键做比较。如果两个可散列对象是相等的，那么它们的散列值一定是一样的。一般来讲用户自定义的类型的对象都是可散列的。\n文本和字节序列 把函数视作对象 💡 可以把函数赋值给变量、传给 其他函数、存储在数据结构中，以及访问函数的属性，供框架和一些工具使用。 一等函数 在 Python 中，函数是一等对象。编程语言理论家把“**一等对象”**定义为满足下述条件的程 序实体:\n在运行时创建 能赋值给变量或数据结构中的元素 能作为参数传给函数 能作为函数的返回结果 在 Python 中，整数、字符串和字典都是一等对象。","title":"Fluent Python"},{"content":"第一章 引言 一些前置概念：\n深度学习（deep learning）：让计算机从经验中学习，根据层次化的概念体系理解世界。深度学习通过其他较简单的表示来表达复杂表示，解决了表示学习中的核心问题。\n知识库（knowledge base）：将知识用形式化的语言进行硬编码，使用逻辑推理规则来自动地理解这些形式化语言的声明。\n机器学习（machine learning）：AI系统需要具备自己获取知识的能力，即从原始数据中提取模式的能力。\n表示学习（represnetation learning）：使用机器学习来发掘表示本身，而不仅仅把标识映射到输出。\n变差因素（factors of variation）：“因素”仅指代影响的不同来源，这些因素通常是不能被直接观测到的量，可以被看作数据的概念或者抽象。如，分析语音时，变差因素包括说话者的年龄、性别、口音和正在说的词语；分析汽车图像时，变差因素包括汽车的位置、颜色、太阳的角度和亮度。\n多层感知机（multilayer perceptron, MLP）：是一个将一组输入值映射到输出值的数学函数。该函数由许多较简单的函数复合而成。\n深度学习模型示意图 深度学习韦恩图 第二章 机器学习基础 学习算法 机器学习算法是一种能够从数据中学习的算法。“对于某类任务T和性能度量P，一个计算机程序被认为可以从经验E中学习是指，通过经验E改进后，它在任务T上由性能度量P衡量的性能有所提升。”\n任务T 通常机器学习任务定义为机器学习系统应该如何处理样本 （example）。样本是指我们从某些希望机器学习系统处理的对象或事件中收集到的已经量化的特征 （feature）的集合。常见的机器学习任务如下：分类、输入缺失分类、回归、转录、机器翻译、结构化输出、异常检测、合成和采样、缺失值填补、去噪、密度估计\n性能度量P “通常性能度量P是特定于系统执行的任务T而言的。”\n经验E “机器学习算法可以大致分类为无监督 （unsupervised）算法和监督 （supervised）算法。\n无监督学习算法 （unsupervised learning algorithm）训练含有很多特征的数据集，然后学习出这个数据集上有用的结构性质。在深度学习中，我们通常要学习生成数据集的整个概率分布，显式地，比如密度估计，或是隐式地，比如合成或去噪。还有一些其他类型的无监督学习任务，例如聚类，将数据集分成相似样本的集合。\n监督学习算法 （supervised learning algorithm）训练含有很多特征的数据集，不过数据集中的样本都有一个标签 （label）或目标 （target）。例如，Iris数据集注明了每个鸢尾花卉样本属于什么品种。监督学习算法通过研究Iris数据集，学习如何根据测量结果将样本划分为3个不同品种。”\n容量、过拟合和欠拟合 在先前未观测到的输入上表现良好的能力被称为泛化 （generalization）。欠拟合是指模型不能在训练集上获得足够低的误差，而过拟合是指训练误差和测试误差之间的差距太大。模型的容量是指其拟合各种函数的能力。容量低的模型可能很难拟合训练集。容量高的模型可能会过拟合。\n正则化 正则化是指修改学习算法，使其降低泛化误差而非训练误差。正则化是机器学习领域的中心问题之一，只有优化能够与其重要性相提并论。\n超参数和验证集 大多数机器学习算法都有超参数，可以设置来控制算法行为。超参数的值不是通过学习算法本身学习出来的。\n交叉验证 当数据集太小时，最常见的是k-折交叉验证过程，将数据集分成k个不重合的子集。测试误差可以估计为k次计算后的平均测试误差。在第i次测试时，数据的第i个子集用于测试集，其他的数据用于训练集。\n估计、偏差和方差 点估计 为一些感兴趣的量提供单个“最优”预测。点估计也可以指输入和目标变量之间关系的估计，我们将这种类型的点估计称为函数估计。\n偏差 估计的偏差被定义为\n方差和标准差 期望的变化程度是多少。\n监督学习算法 监督学习算法是给定一组输入x和输出y的训练集，学习如何关联输入和输出\n无监督学习算法 无监督算法只处理“特征”，不操作监督信号。监督和无监督算法之间的区别没有规范严格的定义，因为没有客观的判断来区分监督者提供的值是特征还是目标。通俗地说，无监督学习的大多数尝试是指从不需要人为注释的样本的分布中抽取信息。\n第三章 深度前馈网络 介绍 深度前馈网络（deep feedforward network），也叫作前馈神经网络（feedforward neural net-work）或者多层感知机（multilayer perceptron，MLP）。“这种模型被称为前向（feedforward）的，是因为信息流过x的函数，流经用于定义f的中间计算过程，最终到达输出y。在模型的输出和模型本身之间没有反馈（feedback）连接。当前馈神经网络被扩展成包含反馈连接时，它们被称为循环神经网络。\n前馈神经网络用许多不同函数复合在一起来表示。该模型与一个有向无环图相关联，而图描述了函数是如何复合在一起的。多个函数连接在一个链上称为链式结构，这些链式结构是神经网络中最常用的结构。链的全长被称为深度。最后一层被称为输出层。\n在神经网络训练过程中，训练数据直接指明了输出层在每一点x上必须做什么，但是训练数据并没有说每个单独的层应该做什么，所以这些层被称为隐藏层。\n基于梯度的学习 在于神经网络的非线性导致大多数我们感兴趣的代价函数都变得非凸。这意味着神经网络的训练通常使用迭代的、基于梯度的优化，仅仅使得代价函数达到一个非常小的值。\n代价函数 神经网络的代价函数或多或少是和其他的参数模型（例如线性模型的代价函数）相同的。\n输出单元 代价函数的选择与输出单元的选择紧密相关。任何可用作输出的神经网络单元，也可以被用作隐藏单元。\n隐藏单元 架构设计 更深层的网络通常能够对每一层使用更少的单元数和更少的参数，并且经常容易泛化到测试集，但是通常也更难以优化。\n万能近似定理表明，一个前馈神经网络如果具有线性输出层和至少一层具有任何一种“挤压”性质的激活函数（例如logistic sigmoid激活函数）的隐藏层，只要给予网络足够数量的隐藏单元，它可以以任意的精度来近似任何从一个有限维空间到另一个有限维空间的Borel可测函数。\n反向传播和其他的微分算法 第四章 正则化 第五章 优化 第六章 卷积网络 第七章 循环网络 第八章 实践 ","permalink":"/posts/deep-learning/","summary":"第一章 引言 一些前置概念：\n深度学习（deep learning）：让计算机从经验中学习，根据层次化的概念体系理解世界。深度学习通过其他较简单的表示来表达复杂表示，解决了表示学习中的核心问题。\n知识库（knowledge base）：将知识用形式化的语言进行硬编码，使用逻辑推理规则来自动地理解这些形式化语言的声明。\n机器学习（machine learning）：AI系统需要具备自己获取知识的能力，即从原始数据中提取模式的能力。\n表示学习（represnetation learning）：使用机器学习来发掘表示本身，而不仅仅把标识映射到输出。\n变差因素（factors of variation）：“因素”仅指代影响的不同来源，这些因素通常是不能被直接观测到的量，可以被看作数据的概念或者抽象。如，分析语音时，变差因素包括说话者的年龄、性别、口音和正在说的词语；分析汽车图像时，变差因素包括汽车的位置、颜色、太阳的角度和亮度。\n多层感知机（multilayer perceptron, MLP）：是一个将一组输入值映射到输出值的数学函数。该函数由许多较简单的函数复合而成。\n深度学习模型示意图 深度学习韦恩图 第二章 机器学习基础 学习算法 机器学习算法是一种能够从数据中学习的算法。“对于某类任务T和性能度量P，一个计算机程序被认为可以从经验E中学习是指，通过经验E改进后，它在任务T上由性能度量P衡量的性能有所提升。”\n任务T 通常机器学习任务定义为机器学习系统应该如何处理样本 （example）。样本是指我们从某些希望机器学习系统处理的对象或事件中收集到的已经量化的特征 （feature）的集合。常见的机器学习任务如下：分类、输入缺失分类、回归、转录、机器翻译、结构化输出、异常检测、合成和采样、缺失值填补、去噪、密度估计\n性能度量P “通常性能度量P是特定于系统执行的任务T而言的。”\n经验E “机器学习算法可以大致分类为无监督 （unsupervised）算法和监督 （supervised）算法。\n无监督学习算法 （unsupervised learning algorithm）训练含有很多特征的数据集，然后学习出这个数据集上有用的结构性质。在深度学习中，我们通常要学习生成数据集的整个概率分布，显式地，比如密度估计，或是隐式地，比如合成或去噪。还有一些其他类型的无监督学习任务，例如聚类，将数据集分成相似样本的集合。\n监督学习算法 （supervised learning algorithm）训练含有很多特征的数据集，不过数据集中的样本都有一个标签 （label）或目标 （target）。例如，Iris数据集注明了每个鸢尾花卉样本属于什么品种。监督学习算法通过研究Iris数据集，学习如何根据测量结果将样本划分为3个不同品种。”\n容量、过拟合和欠拟合 在先前未观测到的输入上表现良好的能力被称为泛化 （generalization）。欠拟合是指模型不能在训练集上获得足够低的误差，而过拟合是指训练误差和测试误差之间的差距太大。模型的容量是指其拟合各种函数的能力。容量低的模型可能很难拟合训练集。容量高的模型可能会过拟合。\n正则化 正则化是指修改学习算法，使其降低泛化误差而非训练误差。正则化是机器学习领域的中心问题之一，只有优化能够与其重要性相提并论。\n超参数和验证集 大多数机器学习算法都有超参数，可以设置来控制算法行为。超参数的值不是通过学习算法本身学习出来的。\n交叉验证 当数据集太小时，最常见的是k-折交叉验证过程，将数据集分成k个不重合的子集。测试误差可以估计为k次计算后的平均测试误差。在第i次测试时，数据的第i个子集用于测试集，其他的数据用于训练集。\n估计、偏差和方差 点估计 为一些感兴趣的量提供单个“最优”预测。点估计也可以指输入和目标变量之间关系的估计，我们将这种类型的点估计称为函数估计。\n偏差 估计的偏差被定义为\n方差和标准差 期望的变化程度是多少。\n监督学习算法 监督学习算法是给定一组输入x和输出y的训练集，学习如何关联输入和输出\n无监督学习算法 无监督算法只处理“特征”，不操作监督信号。监督和无监督算法之间的区别没有规范严格的定义，因为没有客观的判断来区分监督者提供的值是特征还是目标。通俗地说，无监督学习的大多数尝试是指从不需要人为注释的样本的分布中抽取信息。\n第三章 深度前馈网络 介绍 深度前馈网络（deep feedforward network），也叫作前馈神经网络（feedforward neural net-work）或者多层感知机（multilayer perceptron，MLP）。“这种模型被称为前向（feedforward）的，是因为信息流过x的函数，流经用于定义f的中间计算过程，最终到达输出y。在模型的输出和模型本身之间没有反馈（feedback）连接。当前馈神经网络被扩展成包含反馈连接时，它们被称为循环神经网络。","title":"Deep Learning"},{"content":"Chat with Me Loading... Send ","permalink":"/faq/","summary":"faq","title":"FAQ"}]