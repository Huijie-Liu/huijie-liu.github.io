<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>3DGS Tutorial | Jay Tech</title>
<meta name="keywords" content="Learning Note, Deep Learning, Computer Vision, 3DGS">
<meta name="description" content="3DGS 基本思想 3D高斯分布可以通过它们的各向异性协方差矩阵、位置和透明度等参数来有效地表示复杂场景。由于这些参数是通过机器学习方法进行训练的，渲染阶段无需进行大量处理。因此，它可以利用基于瓦片的光栅化器实现快速渲染，从而在性能上有显著的提升。 创新点 Point-Based Rendering：点基渲染直接将三维空间中的点渲染为图像。 Tiled Rasterization：分块光栅化的基本思想是将屏幕划分为多个小块（Tiles），然后在每个小块内进行相关计算和处理（可微分）。这种方法能够显著减少内存流量，从而提高渲染效率。 Spherical Harmonics：球谐函数是一种在球面上表示函数的方法，特别适用于描述球形表面的光照和阴影效果。 基本流程 收集数据
图像
视频-&gt;ffmpeg截取视频帧
ffmpeg -i &lt;VIDEO_PATH&gt; -qscale:v 1 -qmin 1 -vf fps=2 %04d.jpg 输出如下
📦 $FOLDER_PATH ┣ 📂 input ┃ ┣ 📜 000000.jpg ┃ ┣ 📜 000001.jpg ┃ ┣ 📜 ... 获取相机位姿
COLMAP：开源Structure-from-Motion (SfM) 软件，输入images，输出相机位姿
原论文使用的是自带的convert.py，自动调用COLMAP并转换成需要的格式
桌面软件：RealityCapture, Metashape
移动app：Polycam, Record3D（利用了雷达）
输出如下：
📦 $FOLDER_PATH ┣ 📂 (input) ┣ 📂 (distorted) ┣ 📂 images ┣ 📂 sparse ┃ ┣ 📂 0 ┃ ┃ ┣ 📜 points3D.">
<meta name="author" content="Huijie Liu">
<link rel="canonical" href="/posts/3dgs/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="/posts/3dgs/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"
></script>
<script>
  MathJax = {
    tex: {
      displayMath: [
        ["\\[", "\\]"],
        ["$$", "$$"],
      ], 
      inlineMath: [
        ["\\(", "\\)"],
        ["$", "$"],
      ], 
    },
  };
</script>



<meta property="og:title" content="3DGS Tutorial" />
<meta property="og:description" content="3DGS 基本思想 3D高斯分布可以通过它们的各向异性协方差矩阵、位置和透明度等参数来有效地表示复杂场景。由于这些参数是通过机器学习方法进行训练的，渲染阶段无需进行大量处理。因此，它可以利用基于瓦片的光栅化器实现快速渲染，从而在性能上有显著的提升。 创新点 Point-Based Rendering：点基渲染直接将三维空间中的点渲染为图像。 Tiled Rasterization：分块光栅化的基本思想是将屏幕划分为多个小块（Tiles），然后在每个小块内进行相关计算和处理（可微分）。这种方法能够显著减少内存流量，从而提高渲染效率。 Spherical Harmonics：球谐函数是一种在球面上表示函数的方法，特别适用于描述球形表面的光照和阴影效果。 基本流程 收集数据
图像
视频-&gt;ffmpeg截取视频帧
ffmpeg -i &lt;VIDEO_PATH&gt; -qscale:v 1 -qmin 1 -vf fps=2 %04d.jpg 输出如下
📦 $FOLDER_PATH ┣ 📂 input ┃ ┣ 📜 000000.jpg ┃ ┣ 📜 000001.jpg ┃ ┣ 📜 ... 获取相机位姿
COLMAP：开源Structure-from-Motion (SfM) 软件，输入images，输出相机位姿
原论文使用的是自带的convert.py，自动调用COLMAP并转换成需要的格式
桌面软件：RealityCapture, Metashape
移动app：Polycam, Record3D（利用了雷达）
输出如下：
📦 $FOLDER_PATH ┣ 📂 (input) ┣ 📂 (distorted) ┣ 📂 images ┣ 📂 sparse ┃ ┣ 📂 0 ┃ ┃ ┣ 📜 points3D." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/3dgs/" />
<meta property="og:image" content="/assets/images/profile.png" />
<meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-05-23T20:31:53+08:00" />
<meta property="article:modified_time" content="2024-05-23T20:31:53+08:00" />



<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="/assets/images/profile.png" />
<meta name="twitter:title" content="3DGS Tutorial"/>
<meta name="twitter:description" content="3DGS 基本思想 3D高斯分布可以通过它们的各向异性协方差矩阵、位置和透明度等参数来有效地表示复杂场景。由于这些参数是通过机器学习方法进行训练的，渲染阶段无需进行大量处理。因此，它可以利用基于瓦片的光栅化器实现快速渲染，从而在性能上有显著的提升。 创新点 Point-Based Rendering：点基渲染直接将三维空间中的点渲染为图像。 Tiled Rasterization：分块光栅化的基本思想是将屏幕划分为多个小块（Tiles），然后在每个小块内进行相关计算和处理（可微分）。这种方法能够显著减少内存流量，从而提高渲染效率。 Spherical Harmonics：球谐函数是一种在球面上表示函数的方法，特别适用于描述球形表面的光照和阴影效果。 基本流程 收集数据
图像
视频-&gt;ffmpeg截取视频帧
ffmpeg -i &lt;VIDEO_PATH&gt; -qscale:v 1 -qmin 1 -vf fps=2 %04d.jpg 输出如下
📦 $FOLDER_PATH ┣ 📂 input ┃ ┣ 📜 000000.jpg ┃ ┣ 📜 000001.jpg ┃ ┣ 📜 ... 获取相机位姿
COLMAP：开源Structure-from-Motion (SfM) 软件，输入images，输出相机位姿
原论文使用的是自带的convert.py，自动调用COLMAP并转换成需要的格式
桌面软件：RealityCapture, Metashape
移动app：Polycam, Record3D（利用了雷达）
输出如下：
📦 $FOLDER_PATH ┣ 📂 (input) ┣ 📂 (distorted) ┣ 📂 images ┣ 📂 sparse ┃ ┣ 📂 0 ┃ ┃ ┣ 📜 points3D."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "/posts/"
    }
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "3DGS Tutorial",
      "item": "/posts/3dgs/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "3DGS Tutorial",
  "name": "3DGS Tutorial",
  "description": "3DGS 基本思想 3D高斯分布可以通过它们的各向异性协方差矩阵、位置和透明度等参数来有效地表示复杂场景。由于这些参数是通过机器学习方法进行训练的，渲染阶段无需进行大量处理。因此，它可以利用基于瓦片的光栅化器实现快速渲染，从而在性能上有显著的提升。 创新点 Point-Based Rendering：点基渲染直接将三维空间中的点渲染为图像。 Tiled Rasterization：分块光栅化的基本思想是将屏幕划分为多个小块（Tiles），然后在每个小块内进行相关计算和处理（可微分）。这种方法能够显著减少内存流量，从而提高渲染效率。 Spherical Harmonics：球谐函数是一种在球面上表示函数的方法，特别适用于描述球形表面的光照和阴影效果。 基本流程 收集数据\n图像\n视频-\u0026gt;ffmpeg截取视频帧\nffmpeg -i \u0026lt;VIDEO_PATH\u0026gt; -qscale:v 1 -qmin 1 -vf fps=2 %04d.jpg 输出如下\n📦 $FOLDER_PATH ┣ 📂 input ┃ ┣ 📜 000000.jpg ┃ ┣ 📜 000001.jpg ┃ ┣ 📜 ... 获取相机位姿\nCOLMAP：开源Structure-from-Motion (SfM) 软件，输入images，输出相机位姿\n原论文使用的是自带的convert.py，自动调用COLMAP并转换成需要的格式\n桌面软件：RealityCapture, Metashape\n移动app：Polycam, Record3D（利用了雷达）\n输出如下：\n📦 $FOLDER_PATH ┣ 📂 (input) ┣ 📂 (distorted) ┣ 📂 images ┣ 📂 sparse ┃ ┣ 📂 0 ┃ ┃ ┣ 📜 points3D.",
  "keywords": [
    "Learning Note", "Deep Learning", "Computer Vision", "3DGS"
  ],
  "articleBody": "3DGS 基本思想 3D高斯分布可以通过它们的各向异性协方差矩阵、位置和透明度等参数来有效地表示复杂场景。由于这些参数是通过机器学习方法进行训练的，渲染阶段无需进行大量处理。因此，它可以利用基于瓦片的光栅化器实现快速渲染，从而在性能上有显著的提升。 创新点 Point-Based Rendering：点基渲染直接将三维空间中的点渲染为图像。 Tiled Rasterization：分块光栅化的基本思想是将屏幕划分为多个小块（Tiles），然后在每个小块内进行相关计算和处理（可微分）。这种方法能够显著减少内存流量，从而提高渲染效率。 Spherical Harmonics：球谐函数是一种在球面上表示函数的方法，特别适用于描述球形表面的光照和阴影效果。 基本流程 收集数据\n图像\n视频-\u003effmpeg截取视频帧\nffmpeg -i -qscale:v 1 -qmin 1 -vf fps=2 %04d.jpg 输出如下\n📦 $FOLDER_PATH ┣ 📂 input ┃ ┣ 📜 000000.jpg ┃ ┣ 📜 000001.jpg ┃ ┣ 📜 ... 获取相机位姿\nCOLMAP：开源Structure-from-Motion (SfM) 软件，输入images，输出相机位姿\n原论文使用的是自带的convert.py，自动调用COLMAP并转换成需要的格式\n桌面软件：RealityCapture, Metashape\n移动app：Polycam, Record3D（利用了雷达）\n输出如下：\n📦 $FOLDER_PATH ┣ 📂 (input) ┣ 📂 (distorted) ┣ 📂 images ┣ 📂 sparse ┃ ┣ 📂 0 ┃ ┃ ┣ 📜 points3D.bin ┃ ┃ ┣ 📜 images.bin ┃ ┃ ┗ 📜 cameras.bin 训练\n整个训练过程（30,000步）大约需要30-40分钟，在完成7,000步之后会保存一个中间模型。\n输出如下：\n📦 $FOLDER_PATH ┣ 📂 images ┣ 📂 sparse ┣ 📂 output ┃ ┣ 📜 cameras.json ┃ ┣ 📜 cfg_args ┃ ┗ 📜 input.ply ┃ ┣ 📂 point_cloud ┃ ┃ ┣ 📂 iteration_7000 ┃ ┃ ┃ ┗ 📜 point_cloud.ply ┃ ┃ ┣ 📂 iteration_30000 ┃ ┃ ┃ ┗ 📜 point_cloud.ply 可视化\n（官方）在Windows上安装预编译的SIBR viewer （官方）在Ubuntu 上构建SIBR viewer （第三方）SuperSplat，Three.js 原理详解 光栅化：概述 对比NeRF（辐射场）\nNeRF\n$$\\begin{aligned}\u0026C(p)=\\\\\u0026=\\sum_{i=1}^Nc_i(1-\\exp(-\\sigma_i\\delta_i))T_i=\\\\\u0026=\\sum_{i=1}^Nc_i(1-\\exp(-\\sigma_i\\delta_i))\\exp(-\\sum_{j=1}^{i-1}\\sigma_j\\delta_j)=\u0026(1)\\\\\u0026=\\sum_{i=1}^Nc_i\\underbrace{(1-\\exp(-\\sigma_i\\delta_i))}_{\\alpha_i}\\prod_{j=1}^{i-1}\\underbrace{\\exp(-\\sigma_j\\delta_j)}_{1-\\alpha_j}=\\\\\u0026=\\sum_{i=1}^Nc_i\\alpha_i\\underbrace{\\prod_{j=1}^{i-1}(1-\\alpha_j)}_{transmittance}\u0026(2)\\end{aligned}$$ 3DGS\n$$C(p)=\\sum_{i\\in N}c_if_i^{2D}(p)\\underbrace{\\prod_{j=1}^{i-1}(1-f_j^{2D}(p))}_{transmittance}\\quad(3)$$ 公式（3）描述了如何在一个像素中获得颜色值。要渲染整个图像，仍然需要遍历所有的H×W射线，就像在 NeRF 中一样。不过，这个过程更加轻量化：\n预处理排序阶段： 每帧只需在GPU上进行一次预处理排序，使用定制的可微分CUDA 内核实现。这一步骤可以显著加速渲染过程，因为它利用了 GPU 的并行计算能力。 在这一步骤中，所有的三维点根据它们在二维图像平面上的投影位置进行排序，以便快速查找和混合。 预先投影到2D： 对于给定的相机，可以提前将每个三维点的f（p）投影到二维。在遍历像素之前完成这个步骤，这样当高斯函数混合到附近的几个像素时，不需要一遍又一遍地重新投影。 例如，假设有一个三维点（X，Y，2），在给定相机内参和外参矩阵的情况下，可以提前计算出该点在图像平面上的投影位置（2,g）。 直接混合2D高斯： 不需要为每个像素、每条射线、每个三维点运行多层感知机（MLP）模型推断。相反，二维高斯函数可以直接混合到图像上。 这意味着在渲染过程中，计算量大大减少，因为不再需要运行复杂的神经网络推断。 固定的三维点集： 没有模糊性，不需要沿射线选择三维点进行评估，也不需要选择射线采样策略。每个像素的射线重叠的三维点集（公式（3）中的N）在优化后是离散且固定的。 例如，假设某个像素的射线经过了几个三维点，这些点在优化之后是固定的，因此可以直接使用这些点进行渲染，而不需要每次重新采样。 光栅化：实现细节（前向传播） 3D高斯体通过投影矩阵转换到二维相机平面上，获得其投影位置和范围，接着根据深度进行排序，并且从前到后按照不透明度和颜色进行alpha混合，最终组合生成输出图像。\n一个三维高斯分布由以下参数化：\n均值 $\\mu \\in \\mathbb{R}^3$：三维空间中的位置。 协方差 $\\Sigma \\in \\mathbb{R}^{3 \\times 3}$：描述高斯分布的形状和方向。 颜色 $c \\in \\mathbb{R}^3$：颜色向量，通常表示为 RGB 值。 不透明度 $o \\in \\mathbb{R}$：描述高斯分布的透明度。 高斯分布的投影（3D-\u003e2D） 世界坐标系转-\u003e相机坐标系\n渲染相机由其外参 $T_{cw} $描述，它将点从世界坐标系转换到相机坐标系，以及其内参（焦距 $f_x, f_y $和相机平面主点 $(c_x, c_y)$）。我们使用投影矩阵 P 将相机空间的转换到标准化剪辑空间。\n$$T_{cw} = \\begin{bmatrix} R_{cw} \u0026 t_{cw} \\\\ 0 \u0026 1 \\end{bmatrix} \\in SE(3), \\quad P = \\begin{bmatrix} \\frac{2f_x}{w} \u0026 0 \u0026 0 \u0026 0 \\\\ 0 \u0026 \\frac{2f_y}{h} \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 \\frac{f+n}{f-n} \u0026 \\frac{-2fn}{f-n} \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix}$$ 其中 w, h 是输出图像的宽度和高度，n, f 是近剪裁平面和远剪裁平面。我们通过标准透视投影将三维均值 \\mu 投影到像素空间。我们将均值 \\mu 转换为相机坐标系中的 $t \\in \\mathbb{R}^4$，在标准化设备坐标中的 $t' \\in \\mathbb{R}^4$，以及在像素坐标中的 $\\mu' \\in \\mathbb{R}^2$。\n$$t = T_{cw} \\begin{bmatrix} \\mu \\\\ 1 \\end{bmatrix}^T, \\quad t' = Pt, \\quad \\mu' = \\left[ \\begin{array}{c} (w \\cdot \\frac{t'_x}{t'_w} + 1)/2 + c_x \\\\ (h \\cdot \\frac{t'_y}{t'_w} + 1)/2 + c_y \\end{array} \\right]$$ 其中 w 和 h 分别是输出图像的宽度和高度。\n三维高斯-\u003e二维高斯\n透视投影一个三维高斯分布并不会产生二维高斯分布。我们使用一阶泰勒展开近似在相机坐标系中的 t 处的投影。具体来说，我们计算仿射变换矩阵 $J \\in \\mathbb{R}^{2 \\times 3} $如下：\n$$J = \\begin{bmatrix} \\frac{f_x}{t_z} \u0026 0 \u0026 -\\frac{f_x \\cdot t_x}{t_z^2} \\\\ 0 \u0026 \\frac{f_y}{t_z} \u0026 -\\frac{f_y \\cdot t_y}{t_z^2} \\end{bmatrix}$$ 二维协方差矩阵 $\\Sigma' \\in \\mathbb{R}^{2 \\times 2}$ 由下式给出：\n$\\Sigma' = JR_{cw} \\Sigma R_{cw}^T J^T$\n最后，我们用尺度 $s \\in \\mathbb{R}^3$ 和旋转四元数 $q \\in \\mathbb{R}^4$ 来参数化三维协方差$ \\Sigma$ 。我们首先将四元数 $q = (x, y, z, w) $转换为旋转矩阵：\n$$R = \\begin{bmatrix} 1 - 2(y^2 + z^2) \u0026 2(xy - wz) \u0026 2(xz + wy) \\\\ 2(xy + wz) \u0026 1 - 2(x^2 + z^2) \u0026 2(yz - wx) \\\\ 2(xz - wy) \u0026 2(yz + wx) \u0026 1 - 2(x^2 + y^2) \\end{bmatrix}$$ 三维协方差$ \\Sigma $由下式给出：\n$$\\Sigma = RS S^T R^T$$ 其中 $S = \\text{diag}(s) \\in \\mathbb{R}^{3 \\times 3}$。\n高斯分布的深度合成（alpha-blending 计算像素点颜色） 将二维高斯分布划分到 16×16 的瓦片中，并按深度对每个瓦片中的高斯分布进行排序。对于每个高斯分布，我们计算其二维投影协方差（3 sigma）周围的轴对齐边界框，并在其边界框与瓦片相交时将其包括在瓦片中。然后我们应用 [Kerbl et al., 2023] 附录 C 中提出的瓦片排序算法，得到按深度排序的每个瓦片的高斯分布列表。\n步骤\n栅格化每个瓦片中排序后的高斯分布。对于像素 $i$ 的颜色，让 $n$ 索引涉及该像素的 $N$ 个高斯分布：\n$$C_i = \\sum_{n \\leq N} c_n \\cdot \\alpha_n \\cdot T_n， 其中 T_n = \\prod_{m \u003c n} (1 - \\alpha_m)。$$ 我们用二维协方差 $\\Sigma' \\in \\mathbb{R}^{2 \\times 2}$ 和不透明度参数计算 $\\alpha$：\n$$\\alpha_n = o_n \\cdot \\exp(-\\sigma_n)， \\quad \\sigma_n = \\frac{1}{2} \\Delta_n^T \\Sigma'^{-1} \\Delta_n，$$ 其中 $\\Delta \\in \\mathbb{R}^2$ 是像素中心与二维高斯分布中心 $\\mu' \\in \\mathbb{R}^2$ 之间的偏移量。我们在从前到后的过程中计算 $T_n$。\n公式解释\n颜色计算公式：\n$C_i = \\sum_{n \\leq N} c_n \\cdot \\alpha_n \\cdot T_n$，其中 $T_n = \\prod_{m \u003c n} (1 - \\alpha_m)$。\n$c_n$：第 $n$ 个高斯分布的颜色。\n$\\alpha_n$：第 $n$ 个高斯分布的累积不透明度。\n$T_n$：前 $n-1$ 个高斯分布的不透明度积的乘积，表示第 $n$ 个高斯分布的可见度。\n不透明度计算：\n$\\alpha_n = o_n \\cdot \\exp(-\\sigma_n)$\n$o_n$：第 $n$ 个高斯分布的初始不透明度。\n$\\sigma_n$：偏移量的平方距离乘以协方差矩阵的逆。\n偏移量计算：\n$$\\sigma_n = \\frac{1}{2} \\Delta_n^T \\Sigma'^{-1} \\Delta_n$$ $\\Delta_n$：像素中心与高斯分布中心之间的偏移量。\n$\\Sigma'^{-1}$：二维协方差矩阵的逆。\n优化：概述 要从空间中的一堆高斯点获得高质量的图像，需要三个关键组件：良好的初始化、可微分优化和自适应密集化。这些组件可以帮助减少渲染中的尖锐伪影，使图像更平滑和真实。\n初始化\n初始化是指在训练开始时设置三维点的参数。初始化的质量对最终渲染效果至关重要。本文建议使用由 SfM（Structure from Motion）生成的点云来初始化三维点的位置（均值）。SfM 是一种通过分析多张图像来重建三维结构的方法，它可以生成稀疏的点云。\n使用 SfM 生成的点云：\nSfM 通过相机矩阵和多张图像生成三维点云。 这些点云可以用来初始化高斯点的位置，因为它们已经是从真实场景中重建出来的。 随机初始化：\n在初始化时，每个3D点被视为一个球体（即各向同性的协方差矩阵）。 半径的设置基于与相邻点的平均距离，以确保3D世界被适当地覆盖，没有“空洞”。 可微分优化\n在初始化之后，使用简单的随机梯度下降（SGD）来进行优化。场景通过最小化损失函数进行优化，该损失函数是L1损失和结构相似性指数（D-SSIM）损失的组合，用于衡量当前渲染图像与真实图像之间的差异。\n损失函数\nL1 损失：L1损失度量渲染图像和真实图像之间像素值的绝对差异。 D-SSIM 损失：结构相似性指数（SSIM）用于衡量图像的结构相似性。D-SSIM 是其反向度量，用于衡量图像之间的结构不相似性。 自适应密集化\n自适应密集化是优化过程中的一个关键部分，用于解决过度重建和不足重建的问题。自适应密集化在训练期间每隔一段时间（例如每100次SGD步）启动一次。其目的是在现有点无法适当覆盖场景的区域，动态调整点的密度。\n点密集化：\n在具有大梯度的区域分裂点或克隆点。这些区域通常表示高变化率或复杂细节区域，因此需要更多的点来准确表示。对于克隆，创建高斯的复制体并朝着位置梯度移动。对于分裂，用两个较小的高斯替换一个大高斯，按照特定因子减小它们的尺度。 点的剪枝：\n移除那些α值非常低的点。如果一个点的透明度非常高，表示其对最终渲染的贡献很小，因此可以安全地移除这些点以减少计算复杂度。 优化：实现细节（反向传播计算梯度） 给定标量损失 $\\mathcal{L}$ 相对于输出图像每个像素的梯度，我们使用标准链式法则将梯度向后传播到原始输入参数。\nFrobenius 内积\n在下面的推导中，我们将使用 Frobenius 内积来导出矩阵的导数：\n$$\\langle X, Y \\rangle = \\text{Tr}(X^T Y) = \\text{vec}(X)^T \\text{vec}(Y) = \\in \\mathbb{R},$$ 它可以被看作是矩阵点积。Frobenius 内积具有以下性质：\n$$\\begin{aligned} \\langle X, Y \\rangle \u0026= \\langle Y, X \\rangle, \\\\ \\langle X, Y \\rangle \u0026= \\langle X^T, Y^T \\rangle, \\\\ \\langle X, YZ \\rangle \u0026= \\langle Y^T X, Z \\rangle = \\langle X Z^T, Y \\rangle, \\\\ \\langle X, Y + Z \\rangle \u0026= \\langle X, Y \\rangle + \\langle X, Z \\rangle. \\end{aligned}$$ 假设我们有一个标量函数 $f$ 使 $X\\in \\mathbb{R}^{m \\times n}$，且 $X = A$，其中 $A \\in \\mathbb{R}^{m \\times p}$ 和 $Y \\in \\mathbb{R}^{p \\times n}$。我们可以写出 $f$ 相对于任意标量 $x \\in \\mathbb{R}$ 的梯度：\n$$\\frac{\\partial f}{\\partial x} = \\left\\langle \\frac{\\partial f}{\\partial X}, \\frac{\\partial X}{\\partial x} \\right\\rangle,$$ 我们使用简写：\n$$\\partial f = \\left\\langle \\frac{\\partial f}{\\partial X}, \\partial X \\right\\rangle.$$ 这里，$\\frac{\\partial f}{\\partial x} \\in \\mathbb{R}$，$\\frac{\\partial f}{\\partial X} \\in \\mathbb{R}^{m \\times n}$，和 $\\frac{\\partial X}{\\partial x} \\in \\mathbb{R}^{m \\times n}$。\n在这种情况下，继续使用链式法则非常简单。设 $G = \\frac{\\partial f}{\\partial X$，我们有：\n$$\\begin{aligned} \\frac{\\partial f}{\\partial x} \u0026= \\left\\langle G, \\frac{\\partial (AY)}{\\partial x} \\right\\rangle \\\\ \u0026= \\left\\langle G, \\frac{\\partial A}{\\partial x} Y \\right\\rangle + \\left\\langle G, A \\frac{\\partial Y}{\\partial x} \\right\\rangle \\\\ \u0026= \\left\\langle G Y^T, \\frac{\\partial A}{\\partial x} \\right\\rangle + \\left\\langle A^T G, \\frac{\\partial Y}{\\partial x} \\right\\rangle. \\end{aligned}$$ 从这里，我们可以得到 $f$ 相对于 $A$ 和 $Y$ 的梯度的元素：\n$$\\frac{\\partial f}{\\partial A} = G Y^T \\in \\mathbb{R}^{m \\times p}, \\quad \\frac{\\partial f}{\\partial Y} = A^T G \\in \\mathbb{R}^{p \\times n}.$$ 高斯分布深度合成的梯度计算 我们从将像素 $i$ 的损失梯度向后传播到贡献该像素的高斯分布开始。具体来说，对于像素 $i$ 贡献的高斯分布 $i$，我们计算颜色 $\\frac{\\partial \\mathcal{L}}{\\partial c_n} \\in \\mathbb{R^3}$、不透明度 $\\frac{\\partial \\mathcal{L}}{\\partial o_n} \\in \\mathbb{R}$、二维均值 $\\frac{\\partial \\mathcal{L}}{\\partial \\mu_n'} \\in \\mathbb{R}^2$ 和二维协方差 $\\frac{\\partial \\mathcal{L}}{\\partial \\Sigma_n'} \\in \\mathbb{R}^{2 \\times 2}$ 的梯度。\n对于每个通道 $k$的颜色，我们有：\n$$\\frac{\\partial C_i(k)}{\\partial c_n(k)} = \\alpha_n \\cdot T_n$$ 我们保存正向传播过程中计算的最终 $T_N$ 值，并在反向传播过程中计算下一个 $T_{n-1}$ 值：\n$$T_{n-1} = \\frac{T_n}{1 - \\alpha_{n-1}}$$ 对于每个通道 $k$上 $\\alpha$ 的梯度，我们有标量梯度：\n$$\\frac{\\partial C_i(k)}{\\partial \\alpha_n} = c_n(k) \\cdot T_n - \\frac{S_n(k)}{1 - \\alpha_n}$$ 其中，\n$$S_n = \\sum_{m\u003en} c_m \\alpha_m T_m$$ 我们可以在反向传播过程中计算 $S_{n-1}$：\n$$S_N(k) = 0$$ $$S_{n-1}(k) = c_n(k)\\alpha_n T_n + S_n(k)$$ 对于不透明度$o$和 $\\sigma$：\n我们有标量梯度：\n$$\\frac{\\partial \\alpha_n}{\\partial o_n} = \\exp(-\\sigma_n), \\quad \\frac{\\partial \\alpha_n}{\\partial \\sigma_n} = -o_n \\exp(-\\sigma_n)$$ 对于二维均值：\n我们有雅可比矩阵：\n$$\\frac{\\partial \\sigma_n}{\\partial \\mu_n'} = \\frac{\\partial \\sigma_n}{\\partial \\Delta_n} = \\Sigma_n'^{-1} \\Delta_n \\in \\mathbb{R}^2$$ 对于二维协方差：\n我们令 $Y = \\Sigma_n'^{-1}$，其雅可比矩阵从 $\\sigma_n$ 直接得出：\n$$\\frac{\\partial \\sigma_n}{\\partial Y} = \\frac{1}{2} \\Delta_n \\Delta_n^T \\in \\mathbb{R}^{2 \\times 2}$$ 为了继续通过 $Y \\in \\mathbb{R}^{2 \\times 2}$ 进行反向传播，我们令 $G = \\frac{\\partial \\sigma_n}{\\partial Y}$ 并写出相对于标量变量 $x$ 的梯度：\n$$\\frac{\\partial \\sigma_n}{\\partial x} = \\langle G, \\frac{\\partial Y}{\\partial x} \\rangle$$ 我们使用 [Petersen et al., 2008, Dwyer and McPhail, 1948] 的等式，得到：\n$$\\begin{aligned}\\frac{\\partial \\sigma_n}{\\partial x} = \\langle G, -Y \\frac{\\partial \\Sigma_n'^{-1}}{\\partial x} Y \\rangle \\\\ = \\langle -Y^T G Y^T, \\frac{\\partial \\Sigma_n'}{\\partial x} \\rangle \\end{aligned}$$ 因此，相对于 $\\Sigma_n$ 的梯度为：\n$$\\frac{\\partial \\sigma_n}{\\partial \\Sigma_n'} = -\\frac{1}{2} \\Sigma_n'^{-1} \\Delta_n \\Delta_n^T \\Sigma_n'^{-1}$$ 高斯分布投影的梯度计算（2D-\u003e3D） 给定损失函数 $\\mathcal{L}$ 相对于投影后的二维均值 $\\mu$ 和协方差 $\\Sigma$ 的梯度，我们可以继续反向传播单个高斯分布的三维均值 $\\m$ 和协方差 $\\Sigm$ 的梯度。在此，我们一次只处理一个高斯分布，因此省略下标 𝑛，并通过$\\begin{array}{l}\\frac{\\partial\\mathcal{L}}{\\partial\\mu'}\\in\\mathbb{R}^2，\\frac{\\partial\\mathcal{L}}{\\partial\\Sigma'}\\in\\mathbb{R}^{2\\times2}\\end{array}$计算梯度$\\begin{array}{l}\\frac{\\partial\\mathcal{L}}{\\partial\\mu}\\in\\mathbb{R}^3，\\frac{\\partial\\mathcal{L}}{\\partial\\Sigma}\\in\\mathbb{R}^{3\\times3}\\end{array}$\n计算二维均值 $\\mu$ 对相机坐标 $t \\in \\mathbb{R}^4$ 和二维协方差 $\\Sigma'$ 对三维协方差 $\\Sigma$ 及相机坐标 $t$的梯度贡献。\n注意，$\\mu$ 和 $\\Sigma$ 都对 $t$ 的梯度有贡献\n$$\\frac{\\partial\\mathcal{L}}{\\partial t_i}=\\frac{\\partial\\mathcal{L}_{\\mu^{\\prime}}}{\\partial t_i}+\\frac{\\partial\\mathcal{L}_{\\Sigma^{\\prime}}}{\\partial t_i}=\\frac{\\partial\\mathcal{L}}{\\partial\\mu^{\\prime}}\\frac{\\partial\\mu^{\\prime}}{\\partial t_i}+\\langle\\frac{\\partial\\mathcal{L}}{\\partial\\Sigma^{\\prime}},\\frac{\\partial\\Sigma^{\\prime}}{\\partial t_i}\\rangle$$ 对于二维均值 $\\mu$，我们有：\n$$\\frac{\\partial\\mathcal{L}_{\\mu^{\\prime}}}{\\partial t}=\\frac12P^\\top\\begin{bmatrix}w/t_w\u00260\u00260\u0026-w\\cdot t_x/t_w^2\\\\0\u0026h/t_w\u00260\u0026-w\\cdot t_y/t_w^2\\end{bmatrix}^\\top\\frac{\\partial\\mathcal{L}}{\\partial\\mu^{\\prime}}$$ 对于二维协方差 $\\Sigma'$ 对 $\\Sigma$ 和 $t$ 的梯度贡献，$\\Sigma'=T\\Sigma T^\\top$。设 $G = \\frac{\\partial \\mathcal{L}}{\\partial \\Sigma'}$，我们有：\n$\\begin{aligned}\\partial\\mathcal{L}_{\\Sigma^{\\prime}}\u0026=\\langle G,\\partial\\Sigma^{\\prime}\\rangle\\\\\u0026=\\langle G,(\\partial T)\\Sigma T^\\top+T(\\partial\\Sigma)T^\\top+T\\Sigma(\\partial T^\\top)\\rangle\\\\\u0026=\\langle GT\\Sigma^\\top,\\partial T\\rangle+\\langle T^\\top GT,\\partial\\Sigma\\rangle+\\langle G^\\top T\\Sigma,\\partial T\\rangle\\\\\u0026=\\langle GT\\Sigma^\\top+G^\\top T\\Sigma,\\partial T\\rangle+\\langle T^\\top GT,\\partial\\Sigma\\rangle.\\end{aligned}$ 计算相对于协方差矩阵 Σ 的梯度，\n$$\\frac{\\partial \\mathcal{L}}{\\partial \\Sigma} = T^T \\frac{\\partial \\mathcal{L}}{\\partial \\Sigma'} T$$ 我们继续通过 $T = J R_{cw} \\in \\mathbb{R}^{2 \\times 3}$ 传播梯度，对于 $J$ 的梯度，令：\n$$\\partial\\mathcal{L}=\\langle\\frac{\\partial\\mathcal{L}}{\\partial T},(\\partial J)R_{\\mathrm{cw}}\\rangle=\\langle\\frac{\\partial\\mathcal{L}}{\\partial T}R_{\\mathrm{cw}}^\\top,\\partial J\\rangle,\\quad\\mathrm{where~}\\frac{\\partial\\mathcal{L}}{\\partial T}=\\frac{\\partial\\mathcal{L}}{\\partial\\Sigma^{\\prime}}T\\Sigma^\\top+\\frac{\\partial\\mathcal{L}}{\\partial\\Sigma^{\\prime}}^\\top T\\Sigma$$ 我们继续通过 $J$ 对相机坐标 $t \\in \\mathbb{R}^4$ 的贡献进行反向传播：\n$\\frac{\\partial J}{\\partial t_x}=\\begin{bmatrix}0\u00260\u0026-f_x/t_z^2\\\\0\u00260\u00260\\end{bmatrix},\\quad\\frac{\\partial J}{\\partial t_y}=\\begin{bmatrix}0\u00260\u00260\\\\0\u00260\u0026-f_y/t_z^2\\end{bmatrix},\\quad\\frac{\\partial J}{\\partial t_z}=\\begin{bmatrix}-f_x/t_z^2\u00260\u00262f_xt_x/t_z^3\\\\0\u0026-f_y/t_z^2\u00262f_yt_y/t_z^3\\end{bmatrix},\\quad\\frac{\\partial J}{\\partial t_w}=\\mathbf{0}^{2\\times3}$\n我们现在可以将两个梯度 $\\frac{\\partial \\mathcal{L_{\\mu'}}}{\\partial t}$ 和 $\\frac{\\partial \\mathcal{L_{\\Sigma'}}}{\\partial t}$ 合并为 $G = \\frac{\\partial \\mathcal{L}}{\\partial t}$ 并计算相对于三维均值 $\\mu$和视图矩阵 $T_{cw}$ 的全梯度。且有$t=T_\\text{cw}q,\\text{ where }q=\\begin{bmatrix}\\mu\u00261\\end{bmatrix}^\\top$\n$$\\begin{aligned}\\partial\\mathcal{L}\u0026=\\langle G,\\partial t\\rangle=\\langle G,\\partial(T_\\text{cw}q)\\rangle\\\\\u0026=\\langle Gq^\\top,\\partial T_{\\mathrm{cw}}\\rangle+\\langle T_{\\mathrm{cw}}^\\top G,\\partial q\\rangle\\end{aligned}$$ 相对于 $\\mu$ 和 $T_{cw}$ 的梯度：\n$$\\frac{\\partial\\mathcal{L}}{\\partial T_{\\mathrm{cw}}}=\\frac{\\partial\\mathcal{L}}{\\partial t}q^\\top\\in\\mathbb{R}^{4\\times4},\\quad\\frac{\\partial\\mathcal{L}}{\\partial\\mu}=R_{\\mathrm{cw}}^\\top\\begin{bmatrix}\\frac{\\partial\\mathcal{L}}{\\partial t_x}\u0026\\frac{\\partial\\mathcal{L}}{\\partial t_y}\u0026\\frac{\\partial\\mathcal{L}}{\\partial t_z}\\end{bmatrix}^\\top\\in\\mathbb{R}^3$$ 尺度和旋转梯度\n现在我们有 $\\Sigma = M M^3$ 和 $\\frac{\\partial \\mathcal{L}}{\\partial \\Sigma} $。设 $G = \\frac{\\partial \\mathcal{L}}{\\partial \\Sigma}$，我们有：\n$$\\begin{aligned}\\partial\\mathcal{L}\u0026=\\langle G,\\partial\\Sigma\\rangle\\\\\u0026=\\langle G,(\\partial M)M^\\top+M(\\partial M^\\top)\\rangle\\\\\u0026=\\langle GM+G^\\top M,\\partial M\\rangle\\end{aligned}$$ 这给我们：\n$$\\frac{\\partial \\mathcal{L}}{\\partial M} = \\frac{\\partial \\mathcal{L}}{\\partial \\Sigma} M + \\frac{\\partial \\mathcal{L}}{\\partial \\Sigma}^T M $$ 现在我们有 $M = R $，并且 $G = \\frac{\\partial \\mathcal{L}}{\\partial M}$，所以：\n$$\\begin{aligned}\\partial\\mathcal{L}\u0026=\\langle G,\\partial M\\rangle\\\\\u0026=\\langle G,(\\partial R)S\\rangle+\\langle G,R(\\partial S)\\rangle\\\\\u0026=\\langle GS^\\top,\\partial R\\rangle+\\langle R^\\top G,\\partial S\\rangle\\end{aligned}$$ 这给我们：\n$$\\frac{\\partial \\mathcal{L}}{\\partial R} = \\frac{\\partial \\mathcal{L}}{\\partial M} S^T, \\quad \\frac{\\partial \\mathcal{L}}{\\partial S} = R^T \\frac{\\partial \\mathcal{L}}{\\partial M} $$ 旋转矩阵 $R$ 关于四元数参数 $q = (w, x, y, z)$ 的雅可比矩阵是：\n$$\\frac{\\partial R}{\\partial w} = 2 \\begin{bmatrix} 0 \u0026 -z \u0026 y \\\\ z \u0026 0 \u0026 -x \\\\ -y \u0026 x \u0026 0 \\end{bmatrix}, \\quad \\frac{\\partial R}{\\partial x} = 2 \\begin{bmatrix} 0 \u0026 y \u0026 z \\\\ y \u0026 -2x \u0026 -w \\\\ z \u0026 w \u0026 -2x \\end{bmatrix}$$ $$\\frac{\\partial R}{\\partial y} = 2 \\begin{bmatrix} -2y \u0026 x \u0026 w \\\\ x \u0026 0 \u0026 z \\\\ w \u0026 z \u0026 -2y \\end{bmatrix}, \\quad \\frac{\\partial R}{\\partial z} = 2 \\begin{bmatrix} -2z \u0026 -w \u0026 x \\\\ w \u0026 -2z \u0026 y \\\\ x \u0026 y \u0026 0 \\end{bmatrix}$$ 尺度矩阵 $S$ 关于尺度参数 $s = (s_x, s_y, s_z)$ 的雅可比矩阵是：\n$$\\frac{\\partial S}{\\partial s_j} = \\delta_{ij}$$ 其中选择相应的对角元素 $\\frac{\\partial \\mathcal{L}}{\\partial S}$。\nEX：球谐函数 球谐函数在3DGS中并不是必须的\n球谐函数（Spherical Harmonics, SH）\n球谐函数被用来表示视角依赖的颜色，这样可以更好地处理非朗伯反射（如金属表面的镜面反射）。具体来说，通过限制自由度 $\\ell_{\\text{max}}$，每个颜色（红、绿、蓝）可以表示为前$ \\ell\\_{\\text{max}}$ 个球谐函数的线性组合。\n球谐函数是一组定义在球面上的特殊函数，通过选择正整数 $\\ell$ 和 $-\\ell \\leq m \\leq \\ell$ 的一对 $(\\ell, m)$，可以从一个通用公式中导出这些函数。\n公式解释\n球谐函数的通用公式为：\n$$Y_\\ell^m (\\theta, \\phi) = (-1)^m \\sqrt{\\frac{(2\\ell + 1)(\\ell - m)!}{4\\pi (\\ell + m)!}} P_\\ell^m (\\cos \\theta) e^{im\\phi}$$ 其中：\n$\\ell $和 m 是整数，$\\ell \\geq 0，-\\ell \\leq m \\leq \\ell$。\n$\\theta$ 是极角（通常在0到$\\pi$之间），$\\phi$ 是方位角（通常在0到$2\\pi$之间）。\n$P_\\ell^m$ 是缔合勒让德多项式（Associated Legendre Polynomials）。\n球谐函数的性质\n正交性： 球谐函数是正交的，这意味着在球面上的任意两个不同的球谐函数在积分意义下相互独立。 归一化： 球谐函数是归一化的，因此可以形成球面上函数空间的正交基。 简化： 对于小的$\\ell $值，球谐函数公式会显著简化。例如，当 $\\ell $ = 0 时，球谐函数是一个常数，当 $\\ell $ = 1 时，球谐函数也是相对简单的形式。 颜色表示\n对于每个三维高斯点，我们希望学习正确的系数，使得从某个方向看该三维点时，它传达的颜色最接近真实颜色。这是通过以下步骤实现的：\n选择最大自由度：\n选择一个适当的$ \\ell\\_{\\text{max}}$ 值，以限制球谐函数的数量。 线性组合：\n每种颜色（红、绿、蓝）都表示为前$ \\ell\\_{\\text{max}} $个球谐函数的线性组合。对于每个三维高斯点，学习这些线性组合的系数。 视角依赖的颜色计算：\n给定一个观察方向，使用球谐函数和学习到的系数计算该方向上的颜色。 示例\n假设我们选择 $\\ell_{\\text{max}}=2$，则有 5 个球谐函数（$\\ell $= 0, 1, 2 对应的各个 m 值）。我们需要为每个颜色学习 5 个系数。假设对于某个高斯点，这些系数为 $c_{r,i}, c_{g,i}, c_{b,i}$（红、绿、蓝）。\n对于一个特定的观察方向 $(\\theta, \\phi)$，我们可以计算该方向上的颜色：\n$$\\text{Color}(\\theta, \\phi) = \\left( \\sum_{i=1}^5 c_{r,i} Y_i(\\theta, \\phi), \\sum_{i=1}^5 c_{g,i} Y_i(\\theta, \\phi), \\sum_{i=1}^5 c_{b,i} Y_i(\\theta, \\phi) \\right)$$ 总结\n球谐函数提供了一种有效的方法来表示视角依赖的颜色，使得模型能够处理非朗伯反射效果。在具体实现中，通过选择适当的 $\\ell_{\\text{max}}$，并学习每个颜色的球谐函数系数，可以实现高质量的渲染效果。球谐函数的正交性和归一化性质保证了这种表示的数学稳健性和计算效率。 资源消耗 数据准备（快） 使用COLMAP从图像集合中提取SfM信息 训练（较慢） GPU NVIDIA RTX 4090 显存 24 GB 场景 drjohnson playroom bottle scene(dynamic) 图片数量 263 225 48 105 图片分辨率(px) 1332x876 1264x832 1081x1932 1065x1895 训练时间 41 min 17 min 17 min 22 min .ply 文件大小（7000 次迭代） 423 MB（1,789,615个顶点） 403MB（1,618,690个顶点） 48MB 136MB .ply 文件大小（30000 次迭代） 812 MB（3,433,974个顶点） 587MB（2,356,284个顶点） 54MB 324MB 1个顶点约0.25KB\n高斯核均值信息$\\mu$：x, y, z 位置信息 协方差矩阵$\\Sigma$：3x3矩阵，表示高斯核的缩放+旋转 透明度$\\alpha$ SH球谐函数颜色信息：48个（只用到前4阶） 渲染（快） GPU Apple M1 Pro Render window 1920x1080（1080p） 2268x1420（~2K） FPS（2M～3M顶点） 50～60 FPS 20～30 FPS FPS（1M～2M顶点） 60+ FPS 30～40 FPS 由于mac不支持3DGS源代码提供的SIMR viewer，因此目前采用的是基于WebGL的方式（SuperSplat，Three.js），如果在windows平台上通过官方渲染程序运行应该会更快。\n代码分析 局限性 尽管高斯分布渲染（Gaussian Splatting）在整体上取得了出色的结果和令人印象深刻的渲染速度，但这种表示方法的简单性也带来了一些代价。以下是主要的局限性和需要考虑的问题：\n密集化启发式 在优化过程中，引入了各种密集化启发式，以防止模型出现“破损”的高斯点（如过大、过长或冗余的点）。这些密集化措施对于保持模型的稳定性和一致性至关重要。如果没有这些措施，模型可能会在优化过程中产生问题。\n过大或过长的高斯点：如果高斯点的尺寸过大或过长，可能会导致渲染结果失真。 冗余的高斯点：过多的冗余点会增加计算复杂度，而不会显著提高渲染质量。 这些问题在处理超出新视角渲染任务范围的其他任务时可能会进一步放大。\n离散表示的选择 选择离散表示而非连续表示意味着丧失了多层感知机（MLP）的归纳偏置。在 NeRFs 中，MLP 执行隐式插值，平滑处理视角之间的可能不一致性，而三维高斯点对这些不一致性更加敏感，导致上述问题的出现。\nMLP 的插值和平滑：在 NeRF 中，MLP 可以通过插值和平滑减少视角之间的差异。 三维高斯点的敏感性：三维高斯点在处理这些不一致性时更容易出现问题，导致渲染结果不如 NeRF 平滑。 继承的伪影问题 高斯分布渲染继承了一些 NeRF 中存在的已知伪影，这些伪影源于共享的图像形成模型。例如：\n在较少或未见区域的较低质量：在训练数据中较少或未出现的区域，渲染质量可能较低。 靠近图像平面的浮动伪影：在靠近图像平面的区域，可能会出现浮动伪影。 这些问题在高斯分布渲染和 NeRF 中都是存在的，源于它们使用的相似图像形成模型。\n检查点文件大小 检查点文件的大小是另一个需要考虑的属性。尽管新视角渲染尚未被部署到边缘设备，但从磁盘空间的角度来看，三维点的数量和流行的 NeRF MLP 架构占用了相同数量级的磁盘空间，平均而言，高斯分布渲染的文件大小比 NeRF 略大几倍。\n磁盘空间占用：高斯分布渲染由于三维点的数量较多，文件大小略大于 NeRF。 部署考虑：虽然目前部署到边缘设备的需求不大，但未来可能需要考虑文件大小对部署的影响。 数据集 数据集名称 描述 来源 LLFF 本地光场融合（LLFF）数据集包括自然场景的合成图像和真实图像。合成图像由SUNCG和UnrealCV生成，而真实图像包括使用手持手机拍摄的24个场景。 链接 NeRF 神经辐射场（NeRF）数据集包含复杂场景的合成渲染和真实图像。它包括漫射合成360°、真实合成360°和复杂场景的真实图像。 链接 DONeRF DONeRF数据集包括使用Blender和Cycles路径追踪器生成的合成数据，每个场景渲染300张图像。 链接 X3D X3D数据集包括15个专用于X射线3D重建的场景，涵盖医学、生物学、安全和工业应用。 链接 RTMV RTMV是一个用于新视图合成的合成数据集，包括通过光线追踪生成的300,000张图像，涵盖2,000个场景。 链接 Tanks\u0026Temples Tanks\u0026Temples数据集是综合性的，提供了用于基于图像的3D重建管道的中级和高级测试数据集。 链接 RealEstate10K RealEstate10K是一个大型数据集，从10,000个YouTube视频中获取相机位姿，提供通过SLAM和捆绑调整算法获得的轨迹。 链接 ACID 空中海岸线影像数据集（ACID）数据集专注于基于单一图像的延长相机轨迹生成新视图，采用几何和图像合成的混合方法。 链接 SWORD ‘包含遮挡区域的场景’数据集（SWORD）包含1,500个训练视频和290个测试视频，强调用于鲁棒模型训练的近物体和遮挡。 链接 Mip-NeRF 360 Mip-NeRF 360数据集扩展了Mip-NeRF，具有非线性参数化、在线非蒸馏和用于无边界场景的畸变基正则化器。 链接 Deep Blending 用于自由视点基于图像渲染的深度混合数据集包括9个场景，这些场景使用立体相机装备捕获并使用COLMAP和RealityCapture重建。 链接 DTU DTU数据集是多视点立体数据，具有精确的相机定位、结构光扫描仪和不同照明条件的多样化场景。 链接 ScanNet ScanNet是一个室内RGB-D数据集，包含1513个标注扫描，提供90%的表面覆盖率和多样化的3D场景理解任务。 链接 ShapeNet ShapeNet是一个大型3D CAD模型库，对NeRF模型来说非常有价值，强调基于对象的语义标签。 链接 Matterport 3D Matterport-3D数据集包括来自90个建筑规模场景的10,800个全景图视图，具有深度、语义和实例注释。 链接 Replica Replica数据集是一个真实的室内数据集，包含18个场景和35个房间，具有手动调整、语义注释以及基于类和基于实例的标签。 链接 Plenoptic Video 全光视频数据集包含使用全光相机捕获的3D视频，提供逼真和沉浸式的3D体验。 链接 Panoptic CMU全景数据集包含超过150万个实例的3D姿态注释，这些实例出现在社交活动中，并使用同步摄像机捕获，场景多样。 链接 研究现状 功能性 拓展3DGS本身的能力\n动态和变形 拓展的参数列表 在时间 $ t$的 3D 位置：$[x(t), y(t), z(t)]^\\top \\in \\mathbb{R}^3 $ 在时间 $ t$的 3D 旋转，由四元数表示：$[q_x(t), q_y(t), q_z(t), q_w(t)]^\\top \\in \\mathbb{R}^4 $ 缩放因子：$[s_x, s_y, s_z]^\\top \\in \\mathbb{R}^3 $ 表示颜色的球谐系数，具有自由度 k：$h \\in \\mathbb{R}^{3 \\times (k + 1)^2} $ 不透明度：$o \\in \\mathbb{R} $ 动态场景追踪\nDynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis\n4D Gaussian Splatting for Real-Time Dynamic Scene Rendering（CVPR 2024）\n动态场景编辑\nControl4D: Efficient 4D Portrait Editing with Text（CVPR 2024）\nSC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes（CVPR 2024） 扩散模型 文生3D\nGaussianDreamer: Fast Generation from Text to 3D Gaussians by Bridging 2D and 3D Diffusion Models（CVPR 2024）\nGsgen: Text-to-3D using Gaussian Splatting（CVPR 2024）\nDreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation（ICLR 2024 Oral）\n去噪和优化\nGaussianDiffusion: 3D Gaussian Splatting for Denoising Diffusion Probabilistic Models with Structured Noise 利用高斯 Splatting 和 Langevin 动力学扩散模型可加速加速渲染并提高真实感。 优化和加速 Depth-Regularized Optimization for 3D Gaussian Splatting in Few-Shot Images Compact 3D Gaussian Representation for Radiance Field EAGLES: Efficient Accelerated 3D Gaussians with Lightweight EncodingS COLMAP-Free 3D Gaussian Splatting 渲染和着色 Mip-Splatting: Alias-free 3D Gaussian Splatting Relightable 3D Gaussian: Real-time Point Cloud Relighting with BRDF Decomposition and Ray Tracing GS-IR: 3D Gaussian Splatting for Inverse Rendering Multi-Scale 3D Gaussian Splatting for Anti-Aliased Rendering GaussianShader: 3D Gaussian Splatting with Shading Functions for Reflective Surfaces Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering FSGS: Real-Time Few-shot View Synthesis using Gaussian Splatting 压缩 LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and 200+ FPS Compact3D: Compressing Gaussian Splat Radiance Field Models with Vector Quantization 应用性 3DGS的实际应用\n数字化身 基于铰接式或联合式 可动画化 基于头部 SLAM Mesh 提取 可编辑性 参考资料 3DGS概述 ⭐️ 3D Gaussian Splatting原理速通（一）～（四）（29 min watch） ⭐️ Gaussian Splatting is pretty cool!（10 min read） ⭐️ Understanding and Exploring 3D Gaussian Splatting: A Comprehensive Overview（9 min read） 3DGS 官方 Tutorial （2 hours watch） NeRF坑浮沉记3D Gaussian Splatting入门（5 min read） 一文带你入门 3D Gaussian Splatting（10 min read） 原理详解 ⭐️ A Comprehensive Overview of Gaussian Splatting（12 min read） Mathematical Supplement for the gsplat Library（30 min read） NumByNum 3D Gaussian Splatting Reviewed（29 min read） EWA Splatting （30+ min read） 研究现状 ",
  "wordCount" : "2020",
  "inLanguage": "en",
  "image": "/assets/images/profile.png""datePublished": "2024-05-23T20:31:53+08:00",
  "dateModified": "2024-05-23T20:31:53+08:00",
  "author":[{
    "@type": "Person",
    "name": "Huijie Liu"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/posts/3dgs/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Jay Tech",
    "logo": {
      "@type": "ImageObject",
      "url": "/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/" accesskey="h" title="Jay Tech (Alt + H)">Jay Tech</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="/faq/" title="FAQ">
                    <span>FAQ</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="/">Home</a>&nbsp;»&nbsp;<a href="/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      3DGS Tutorial
    </h1>
    <div class="post-meta"><span title='2024-05-23 20:31:53 +0800 CST'>May 23, 2024</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;Huijie Liu

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#3dgs" aria-label="3DGS">3DGS</a><ul>
                        
                <li>
                    <a href="#%e5%9f%ba%e6%9c%ac%e6%b5%81%e7%a8%8b" aria-label="基本流程">基本流程</a></li>
                <li>
                    <a href="#%e5%8e%9f%e7%90%86%e8%af%a6%e8%a7%a3" aria-label="原理详解">原理详解</a><ul>
                        
                <li>
                    <a href="#%e5%85%89%e6%a0%85%e5%8c%96%e6%a6%82%e8%bf%b0" aria-label="光栅化：概述">光栅化：概述</a></li>
                <li>
                    <a href="#%e5%85%89%e6%a0%85%e5%8c%96%e5%ae%9e%e7%8e%b0%e7%bb%86%e8%8a%82%e5%89%8d%e5%90%91%e4%bc%a0%e6%92%ad" aria-label="光栅化：实现细节（前向传播）">光栅化：实现细节（前向传播）</a><ul>
                        
                <li>
                    <a href="#%e9%ab%98%e6%96%af%e5%88%86%e5%b8%83%e7%9a%84%e6%8a%95%e5%bd%b13d-2d" aria-label="高斯分布的投影（3D-&gt;2D）">高斯分布的投影（3D-&gt;2D）</a></li>
                <li>
                    <a href="#%e9%ab%98%e6%96%af%e5%88%86%e5%b8%83%e7%9a%84%e6%b7%b1%e5%ba%a6%e5%90%88%e6%88%90alpha-blending-%e8%ae%a1%e7%ae%97%e5%83%8f%e7%b4%a0%e7%82%b9%e9%a2%9c%e8%89%b2" aria-label="高斯分布的深度合成（alpha-blending 计算像素点颜色）">高斯分布的深度合成（alpha-blending 计算像素点颜色）</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%bc%98%e5%8c%96%e6%a6%82%e8%bf%b0" aria-label="优化：概述">优化：概述</a></li>
                <li>
                    <a href="#%e4%bc%98%e5%8c%96%e5%ae%9e%e7%8e%b0%e7%bb%86%e8%8a%82%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad%e8%ae%a1%e7%ae%97%e6%a2%af%e5%ba%a6" aria-label="优化：实现细节（反向传播计算梯度）">优化：实现细节（反向传播计算梯度）</a><ul>
                        
                <li>
                    <a href="#%e9%ab%98%e6%96%af%e5%88%86%e5%b8%83%e6%b7%b1%e5%ba%a6%e5%90%88%e6%88%90%e7%9a%84%e6%a2%af%e5%ba%a6%e8%ae%a1%e7%ae%97" aria-label="高斯分布深度合成的梯度计算">高斯分布深度合成的梯度计算</a></li>
                <li>
                    <a href="#%e9%ab%98%e6%96%af%e5%88%86%e5%b8%83%e6%8a%95%e5%bd%b1%e7%9a%84%e6%a2%af%e5%ba%a6%e8%ae%a1%e7%ae%972d-3d" aria-label="高斯分布投影的梯度计算（2D-&gt;3D）">高斯分布投影的梯度计算（2D-&gt;3D）</a></li></ul>
                </li>
                <li>
                    <a href="#ex%e7%90%83%e8%b0%90%e5%87%bd%e6%95%b0" aria-label="EX：球谐函数">EX：球谐函数</a></li></ul>
                </li>
                <li>
                    <a href="#%e8%b5%84%e6%ba%90%e6%b6%88%e8%80%97" aria-label="资源消耗">资源消耗</a><ul>
                        
                <li>
                    <a href="#%e6%95%b0%e6%8d%ae%e5%87%86%e5%a4%87%e5%bf%ab" aria-label="数据准备（快）">数据准备（快）</a></li>
                <li>
                    <a href="#%e8%ae%ad%e7%bb%83%e8%be%83%e6%85%a2" aria-label="训练（较慢）">训练（较慢）</a></li>
                <li>
                    <a href="#%e6%b8%b2%e6%9f%93%e5%bf%ab" aria-label="渲染（快）">渲染（快）</a></li></ul>
                </li>
                <li>
                    <a href="#%e4%bb%a3%e7%a0%81%e5%88%86%e6%9e%90" aria-label="代码分析">代码分析</a></li>
                <li>
                    <a href="#%e5%b1%80%e9%99%90%e6%80%a7" aria-label="局限性">局限性</a><ul>
                        
                <li>
                    <a href="#%e5%af%86%e9%9b%86%e5%8c%96%e5%90%af%e5%8f%91%e5%bc%8f" aria-label="密集化启发式">密集化启发式</a></li>
                <li>
                    <a href="#%e7%a6%bb%e6%95%a3%e8%a1%a8%e7%a4%ba%e7%9a%84%e9%80%89%e6%8b%a9" aria-label="离散表示的选择">离散表示的选择</a></li>
                <li>
                    <a href="#%e7%bb%a7%e6%89%bf%e7%9a%84%e4%bc%aa%e5%bd%b1%e9%97%ae%e9%a2%98" aria-label="继承的伪影问题">继承的伪影问题</a></li>
                <li>
                    <a href="#%e6%a3%80%e6%9f%a5%e7%82%b9%e6%96%87%e4%bb%b6%e5%a4%a7%e5%b0%8f" aria-label="检查点文件大小">检查点文件大小</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#%e6%95%b0%e6%8d%ae%e9%9b%86" aria-label="数据集">数据集</a></li>
                <li>
                    <a href="#%e7%a0%94%e7%a9%b6%e7%8e%b0%e7%8a%b6" aria-label="研究现状">研究现状</a><ul>
                        
                <li>
                    <a href="#%e5%8a%9f%e8%83%bd%e6%80%a7" aria-label="功能性">功能性</a><ul>
                        
                <li>
                    <a href="#%e5%8a%a8%e6%80%81%e5%92%8c%e5%8f%98%e5%bd%a2" aria-label="动态和变形">动态和变形</a></li>
                <li>
                    <a href="#%e6%89%a9%e6%95%a3%e6%a8%a1%e5%9e%8b" aria-label="扩散模型">扩散模型</a></li>
                <li>
                    <a href="#%e4%bc%98%e5%8c%96%e5%92%8c%e5%8a%a0%e9%80%9f" aria-label="优化和加速">优化和加速</a></li>
                <li>
                    <a href="#%e6%b8%b2%e6%9f%93%e5%92%8c%e7%9d%80%e8%89%b2" aria-label="渲染和着色">渲染和着色</a></li>
                <li>
                    <a href="#%e5%8e%8b%e7%bc%a9" aria-label="压缩">压缩</a></li></ul>
                </li>
                <li>
                    <a href="#%e5%ba%94%e7%94%a8%e6%80%a7" aria-label="应用性">应用性</a><ul>
                        
                <li>
                    <a href="#%e6%95%b0%e5%ad%97%e5%8c%96%e8%ba%ab" aria-label="数字化身">数字化身</a></li>
                <li>
                    <a href="#slam" aria-label="SLAM">SLAM</a></li>
                <li>
                    <a href="#mesh-%e6%8f%90%e5%8f%96" aria-label="Mesh 提取">Mesh 提取</a></li>
                <li>
                    <a href="#%e5%8f%af%e7%bc%96%e8%be%91%e6%80%a7" aria-label="可编辑性">可编辑性</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99" aria-label="参考资料">参考资料</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="3dgs">3DGS<a hidden class="anchor" aria-hidden="true" href="#3dgs">#</a></h1>
<ul>
<li>基本思想
<ul>
<li>3D高斯分布可以通过它们的各向异性协方差矩阵、位置和透明度等参数来有效地表示复杂场景。由于这些参数是通过机器学习方法进行训练的，渲染阶段无需进行大量处理。因此，它可以利用基于瓦片的光栅化器实现快速渲染，从而在性能上有显著的提升。</li>
<li><img loading="lazy" src="./assets/%28null%29#center" alt="img"  />
</li>
</ul>
</li>
<li>创新点
<ul>
<li><strong>Point-Based Rendering</strong>：点基渲染直接将三维空间中的点渲染为图像。</li>
<li><strong>Tiled Rasterization</strong>：分块光栅化的基本思想是将屏幕划分为多个小块（Tiles），然后在每个小块内进行相关计算和处理（可微分）。这种方法能够显著减少内存流量，从而提高渲染效率。</li>
<li><strong>Spherical Harmonics</strong>：球谐函数是一种在球面上表示函数的方法，特别适用于描述球形表面的光照和阴影效果。</li>
</ul>
</li>
</ul>
<h2 id="基本流程">基本流程<a hidden class="anchor" aria-hidden="true" href="#基本流程">#</a></h2>
<ol>
<li>
<p>收集数据</p>
<ol>
<li>
<p>图像</p>
</li>
<li>
<p>视频-&gt;ffmpeg截取视频帧</p>
<ol>
<li>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Bash" data-lang="Bash"><span class="line"><span class="cl">ffmpeg -i &lt;VIDEO_PATH&gt; -qscale:v <span class="m">1</span> -qmin <span class="m">1</span> -vf <span class="nv">fps</span><span class="o">=</span><span class="m">2</span> %04d.jpg
</span></span></code></pre></div></li>
</ol>
</li>
<li>
<p>输出如下</p>
</li>
<li>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Bash" data-lang="Bash"><span class="line"><span class="cl">📦 <span class="nv">$FOLDER_PATH</span>
</span></span><span class="line"><span class="cl"> ┣ 📂 input
</span></span><span class="line"><span class="cl"> ┃ ┣ 📜 000000.jpg
</span></span><span class="line"><span class="cl"> ┃ ┣ 📜 000001.jpg
</span></span><span class="line"><span class="cl"> ┃ ┣ 📜 ...
</span></span></code></pre></div></li>
</ol>
</li>
<li>
<p>获取相机位姿</p>
<ol>
<li>
<p><a href="https://arc.net/l/quote/qyzmvpxq">COLMAP</a>：开源Structure-from-Motion (SfM) 软件，输入images，输出相机位姿</p>
<ol>
<li>
<blockquote>
<p>原论文使用的是自带的convert.py，自动调用COLMAP并转换成需要的格式</p>
</blockquote>
</li>
</ol>
</li>
<li>
<p>桌面软件：<a href="https://www.capturingreality.com/">RealityCapture</a>, <a href="https://www.agisoft.com/">Metashape</a></p>
</li>
<li>
<p>移动app：<a href="https://poly.cam/">Polycam</a>, <a href="https://record3d.app/">Record3D</a>（利用了雷达）</p>
</li>
<li>
<p>输出如下：</p>
</li>
<li>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Bash" data-lang="Bash"><span class="line"><span class="cl">📦 <span class="nv">$FOLDER_PATH</span>
</span></span><span class="line"><span class="cl"> ┣ 📂 <span class="o">(</span>input<span class="o">)</span>
</span></span><span class="line"><span class="cl"> ┣ 📂 <span class="o">(</span>distorted<span class="o">)</span>
</span></span><span class="line"><span class="cl"> ┣ 📂 images
</span></span><span class="line"><span class="cl"> ┣ 📂 sparse
</span></span><span class="line"><span class="cl"> ┃ ┣ 📂 <span class="m">0</span>
</span></span><span class="line"><span class="cl"> ┃ ┃ ┣ 📜 points3D.bin
</span></span><span class="line"><span class="cl"> ┃ ┃ ┣ 📜 images.bin
</span></span><span class="line"><span class="cl"> ┃ ┃ ┗ 📜 cameras.bin
</span></span></code></pre></div></li>
</ol>
</li>
<li>
<p>训练</p>
<ol>
<li>
<p>整个训练过程（30,000步）大约需要30-40分钟，在完成7,000步之后会保存一个中间模型。</p>
</li>
<li>
<p>输出如下：</p>
</li>
<li>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-Bash" data-lang="Bash"><span class="line"><span class="cl">📦 <span class="nv">$FOLDER_PATH</span>
</span></span><span class="line"><span class="cl"> ┣ 📂 images
</span></span><span class="line"><span class="cl"> ┣ 📂 sparse
</span></span><span class="line"><span class="cl"> ┣ 📂 output
</span></span><span class="line"><span class="cl"> ┃ ┣ 📜 cameras.json
</span></span><span class="line"><span class="cl"> ┃ ┣ 📜 cfg_args
</span></span><span class="line"><span class="cl"> ┃ ┗ 📜 input.ply
</span></span><span class="line"><span class="cl"> ┃ ┣ 📂 point_cloud
</span></span><span class="line"><span class="cl"> ┃ ┃ ┣ 📂 iteration_7000
</span></span><span class="line"><span class="cl"> ┃ ┃ ┃ ┗ 📜 point_cloud.ply
</span></span><span class="line"><span class="cl"> ┃ ┃ ┣ 📂 iteration_30000
</span></span><span class="line"><span class="cl"> ┃ ┃ ┃ ┗ 📜 point_cloud.ply
</span></span></code></pre></div></li>
</ol>
</li>
<li>
<p>可视化</p>
<ol>
<li>（官方）在Windows上安装预编译的SIBR viewer</li>
<li>（官方）在Ubuntu 上构建SIBR viewer</li>
<li>（第三方）<a href="https://playcanvas.com/supersplat/editor">SuperSplat</a>，<a href="https://projects.markkellogg.org/threejs/demo_gaussian_splats_3d.php">Three.js</a></li>
</ol>
</li>
</ol>
<h2 id="原理详解">原理详解<a hidden class="anchor" aria-hidden="true" href="#原理详解">#</a></h2>
<h3 id="光栅化概述">光栅化：概述<a hidden class="anchor" aria-hidden="true" href="#光栅化概述">#</a></h3>
<ul>
<li>
<p>对比NeRF（辐射场）</p>
<ul>
<li>
<p>NeRF</p>
<ul>
<li>$$\begin{aligned}&C(p)=\\&=\sum_{i=1}^Nc_i(1-\exp(-\sigma_i\delta_i))T_i=\\&=\sum_{i=1}^Nc_i(1-\exp(-\sigma_i\delta_i))\exp(-\sum_{j=1}^{i-1}\sigma_j\delta_j)=&(1)\\&=\sum_{i=1}^Nc_i\underbrace{(1-\exp(-\sigma_i\delta_i))}_{\alpha_i}\prod_{j=1}^{i-1}\underbrace{\exp(-\sigma_j\delta_j)}_{1-\alpha_j}=\\&=\sum_{i=1}^Nc_i\alpha_i\underbrace{\prod_{j=1}^{i-1}(1-\alpha_j)}_{transmittance}&(2)\end{aligned}$$</li>
</ul>
</li>
<li>
<p>3DGS</p>
<ul>
<li>
$$C(p)=\sum_{i\in N}c_if_i^{2D}(p)\underbrace{\prod_{j=1}^{i-1}(1-f_j^{2D}(p))}_{transmittance}\quad(3)$$
</li>
<li>
<p><img loading="lazy" src="./assets/%28null%29-20240523202652029.%28null%29#center" alt="img"  />
</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>公式（3）描述了如何在一个像素中获得颜色值。要渲染整个图像，仍然需要遍历所有的H×W射线，就像在 NeRF 中一样。不过，这个过程更加轻量化：</p>
<p><img loading="lazy" src="./assets/%28null%29-20240523202734762.%28null%29#center" alt="img"  />
</p>
<p><img loading="lazy" src="./assets/%28null%29-20240523202731631.%28null%29#center" alt="img"  />
</p>
<ol>
<li>预处理排序阶段：
<ol>
<li>每帧只需在GPU上进行一次预处理排序，使用定制的可微分CUDA 内核实现。这一步骤可以显著加速渲染过程，因为它利用了 GPU 的并行计算能力。</li>
<li>在这一步骤中，所有的三维点根据它们在二维图像平面上的投影位置进行排序，以便快速查找和混合。</li>
<li><img loading="lazy" src="./assets/%28null%29-20240523202744678.%28null%29#center" alt="img"  />
</li>
</ol>
</li>
<li>预先投影到2D：
<ol>
<li>对于给定的相机，可以提前将每个三维点的f（p）投影到二维。在遍历像素之前完成这个步骤，这样当高斯函数混合到附近的几个像素时，不需要一遍又一遍地重新投影。</li>
<li>例如，假设有一个三维点（X，Y，2），在给定相机内参和外参矩阵的情况下，可以提前计算出该点在图像平面上的投影位置（2,g）。</li>
</ol>
</li>
<li>直接混合2D高斯：
<ol>
<li>不需要为每个像素、每条射线、每个三维点运行多层感知机（MLP）模型推断。相反，二维高斯函数可以直接混合到图像上。</li>
<li>这意味着在渲染过程中，计算量大大减少，因为不再需要运行复杂的神经网络推断。</li>
</ol>
</li>
<li>固定的三维点集：
<ol>
<li>没有模糊性，不需要沿射线选择三维点进行评估，也不需要选择射线采样策略。每个像素的射线重叠的三维点集（公式（3）中的N）在优化后是离散且固定的。</li>
<li>例如，假设某个像素的射线经过了几个三维点，这些点在优化之后是固定的，因此可以直接使用这些点进行渲染，而不需要每次重新采样。</li>
</ol>
</li>
</ol>
<h3 id="光栅化实现细节前向传播">光栅化：实现细节（前向传播）<a hidden class="anchor" aria-hidden="true" href="#光栅化实现细节前向传播">#</a></h3>
<p>3D高斯体通过投影矩阵转换到二维相机平面上，获得其投影位置和范围，接着根据深度进行排序，并且从前到后按照不透明度和颜色进行alpha混合，最终组合生成输出图像。</p>
<p>一个三维高斯分布由以下参数化：</p>
<ul>
<li><strong>均值</strong> $\mu \in \mathbb{R}^3$：三维空间中的位置。</li>
<li><strong>协方差</strong> $\Sigma \in \mathbb{R}^{3 \times 3}$：描述高斯分布的形状和方向。</li>
<li><strong>颜色</strong> $c \in \mathbb{R}^3$：颜色向量，通常表示为 RGB 值。</li>
<li><strong>不透明度</strong> $o \in \mathbb{R}$：描述高斯分布的透明度。</li>
</ul>
<h4 id="高斯分布的投影3d-2d"><strong>高斯分布的投影（3D-&gt;2D）</strong><a hidden class="anchor" aria-hidden="true" href="#高斯分布的投影3d-2d">#</a></h4>
<ol>
<li>
<p>世界坐标系转-&gt;相机坐标系</p>
<ol>
<li>
<p>渲染相机由其外参 $T_{cw} $描述，它将点从世界坐标系转换到相机坐标系，以及其内参（焦距 $f_x, f_y $和相机平面主点 $(c_x, c_y)$）。我们使用投影矩阵 P 将相机空间的转换到标准化剪辑空间。</p>
</li>
<li>
$$T_{cw} = \begin{bmatrix} R_{cw} & t_{cw} \\ 0 & 1 \end{bmatrix} \in SE(3), \quad P = \begin{bmatrix} \frac{2f_x}{w} & 0 & 0 & 0 \\ 0 & \frac{2f_y}{h} & 0 & 0 \\ 0 & 0 & \frac{f+n}{f-n} & \frac{-2fn}{f-n} \\ 0 & 0 & 0 & 1 \end{bmatrix}$$
</li>
<li>
<p>其中 w, h 是输出图像的宽度和高度，n, f 是近剪裁平面和远剪裁平面。我们通过标准透视投影将三维均值 \mu 投影到像素空间。我们将均值 \mu 转换为相机坐标系中的 $t \in \mathbb{R}^4$，在标准化设备坐标中的 $t' \in \mathbb{R}^4$，以及在像素坐标中的 $\mu' \in \mathbb{R}^2$。</p>
</li>
<li>
$$t = T_{cw} \begin{bmatrix} \mu \\ 1 \end{bmatrix}^T, \quad t' = Pt, \quad \mu' = \left[ \begin{array}{c} (w \cdot \frac{t'_x}{t'_w} + 1)/2 + c_x \\ (h \cdot \frac{t'_y}{t'_w} + 1)/2 + c_y \end{array} \right]$$
</li>
<li>
<p>其中 w 和 h 分别是输出图像的宽度和高度。</p>
</li>
</ol>
</li>
<li>
<p>三维高斯-&gt;二维高斯</p>
<ol>
<li>
<p>透视投影一个三维高斯分布并不会产生二维高斯分布。我们使用一阶泰勒展开近似在相机坐标系中的 t 处的投影。具体来说，我们计算仿射变换矩阵 $J \in \mathbb{R}^{2 \times 3} $如下：</p>
</li>
<li>
$$J = \begin{bmatrix} \frac{f_x}{t_z} & 0 & -\frac{f_x \cdot t_x}{t_z^2} \\ 0 & \frac{f_y}{t_z} & -\frac{f_y \cdot t_y}{t_z^2} \end{bmatrix}$$
</li>
<li>
<p>二维协方差矩阵 $\Sigma' \in \mathbb{R}^{2 \times 2}$ 由下式给出：</p>
</li>
<li>
<p>$\Sigma' = JR_{cw} \Sigma R_{cw}^T J^T$</p>
</li>
<li>
<p>最后，我们用尺度 $s \in \mathbb{R}^3$ 和旋转四元数 $q \in \mathbb{R}^4$ 来参数化三维协方差$ \Sigma$ 。我们首先将四元数 $q = (x, y, z, w) $转换为旋转矩阵：</p>
</li>
<li>
$$R = \begin{bmatrix} 1 - 2(y^2 + z^2) & 2(xy - wz) & 2(xz + wy) \\ 2(xy + wz) & 1 - 2(x^2 + z^2) & 2(yz - wx) \\ 2(xz - wy) & 2(yz + wx) & 1 - 2(x^2 + y^2) \end{bmatrix}$$
</li>
<li>
<p>三维协方差$ \Sigma $由下式给出：</p>
</li>
<li>
$$\Sigma = RS S^T R^T$$
</li>
<li>
<p>其中 $S = \text{diag}(s) \in \mathbb{R}^{3 \times 3}$。</p>
</li>
</ol>
</li>
</ol>
<h4 id="高斯分布的深度合成alpha-blending-计算像素点颜色">高斯分布的深度合成（alpha-blending 计算像素点颜色）<a hidden class="anchor" aria-hidden="true" href="#高斯分布的深度合成alpha-blending-计算像素点颜色">#</a></h4>
<p>将二维高斯分布划分到 16×16 的瓦片中，并按深度对每个瓦片中的高斯分布进行排序。对于每个高斯分布，我们计算其二维投影协方差（3 sigma）周围的轴对齐边界框，并在其边界框与瓦片相交时将其包括在瓦片中。然后我们应用 [Kerbl et al., 2023] 附录 C 中提出的瓦片排序算法，得到按深度排序的每个瓦片的高斯分布列表。</p>
<ul>
<li>
<p>步骤</p>
<ul>
<li>
<p>栅格化每个瓦片中排序后的高斯分布。对于像素 $i$ 的颜色，让 $n$ 索引涉及该像素的 $N$ 个高斯分布：</p>
</li>
<li>
$$C_i = \sum_{n \leq N} c_n \cdot \alpha_n \cdot T_n， 其中 T_n = \prod_{m < n} (1 - \alpha_m)。$$
</li>
<li>
<p>我们用二维协方差 $\Sigma' \in \mathbb{R}^{2 \times 2}$ 和不透明度参数计算 $\alpha$：</p>
</li>
<li>
$$\alpha_n = o_n \cdot \exp(-\sigma_n)， \quad \sigma_n = \frac{1}{2} \Delta_n^T \Sigma'^{-1} \Delta_n，$$
</li>
<li>
<p>其中 $\Delta \in \mathbb{R}^2$ 是像素中心与二维高斯分布中心 $\mu' \in \mathbb{R}^2$ 之间的偏移量。我们在从前到后的过程中计算 $T_n$。</p>
</li>
</ul>
</li>
<li>
<p>公式解释</p>
<ul>
<li>
<p><strong>颜色计算公式</strong>：</p>
<ol>
<li>
<p>$C_i = \sum_{n \leq N} c_n \cdot \alpha_n \cdot T_n$，其中 $T_n = \prod_{m < n} (1 - \alpha_m)$。</p>
</li>
<li>
<p>$c_n$：第 $n$ 个高斯分布的颜色。</p>
</li>
<li>
<p>$\alpha_n$：第 $n$ 个高斯分布的累积不透明度。</p>
</li>
<li>
<p>$T_n$：前 $n-1$ 个高斯分布的不透明度积的乘积，表示第 $n$ 个高斯分布的可见度。</p>
</li>
</ol>
</li>
<li>
<p><strong>不透明度计算</strong>：</p>
<ol>
<li>
<p>$\alpha_n = o_n \cdot \exp(-\sigma_n)$</p>
</li>
<li>
<p>$o_n$：第 $n$ 个高斯分布的初始不透明度。</p>
</li>
<li>
<p>$\sigma_n$：偏移量的平方距离乘以协方差矩阵的逆。</p>
</li>
</ol>
</li>
<li>
<p><strong>偏移量计算</strong>：</p>
<ol>
<li>
$$\sigma_n = \frac{1}{2} \Delta_n^T \Sigma'^{-1} \Delta_n$$
</li>
<li>
<p>$\Delta_n$：像素中心与高斯分布中心之间的偏移量。</p>
</li>
<li>
<p>$\Sigma'^{-1}$：二维协方差矩阵的逆。</p>
</li>
</ol>
</li>
</ul>
</li>
</ul>
<h3 id="优化概述">优化：概述<a hidden class="anchor" aria-hidden="true" href="#优化概述">#</a></h3>
<p>要从空间中的一堆高斯点获得高质量的图像，需要三个关键组件：良好的初始化、可微分优化和自适应密集化。这些组件可以帮助减少渲染中的尖锐伪影，使图像更平滑和真实。</p>
<p><img loading="lazy" src="./assets/%28null%29-20240523202800392.%28null%29#center" alt="img"  />
</p>
<ol>
<li>
<p>初始化</p>
<ol>
<li>
<p>初始化是指在训练开始时设置三维点的参数。初始化的质量对最终渲染效果至关重要。本文建议使用由 SfM（Structure from Motion）生成的点云来初始化三维点的位置（均值）。SfM 是一种通过分析多张图像来重建三维结构的方法，它可以生成稀疏的点云。</p>
</li>
<li>
<p>使用 SfM 生成的点云：</p>
<ul>
<li>SfM 通过相机矩阵和多张图像生成三维点云。</li>
<li>这些点云可以用来初始化高斯点的位置，因为它们已经是从真实场景中重建出来的。</li>
</ul>
</li>
<li>
<p>随机初始化：</p>
<ul>
<li>在初始化时，每个3D点被视为一个球体（即各向同性的协方差矩阵）。</li>
<li>半径的设置基于与相邻点的平均距离，以确保3D世界被适当地覆盖，没有“空洞”。</li>
</ul>
</li>
<li>
<p><img loading="lazy" src="./assets/%28null%29-20240523202803357.%28null%29#center" alt="img"  />
</p>
</li>
</ol>
</li>
<li>
<p>可微分优化</p>
<ol>
<li>
<p>在初始化之后，使用简单的随机梯度下降（SGD）来进行优化。场景通过最小化损失函数进行优化，该损失函数是L1损失和结构相似性指数（D-SSIM）损失的组合，用于衡量当前渲染图像与真实图像之间的差异。</p>
</li>
<li>
<p>损失函数</p>
<ul>
<li>L1 损失：L1损失度量渲染图像和真实图像之间像素值的绝对差异。</li>
<li>D-SSIM 损失：结构相似性指数（SSIM）用于衡量图像的结构相似性。D-SSIM 是其反向度量，用于衡量图像之间的结构不相似性。</li>
</ul>
</li>
</ol>
</li>
<li>
<p>自适应密集化</p>
<ol>
<li>
<p>自适应密集化是优化过程中的一个关键部分，用于解决过度重建和不足重建的问题。自适应密集化在训练期间每隔一段时间（例如每100次SGD步）启动一次。其目的是在现有点无法适当覆盖场景的区域，动态调整点的密度。</p>
</li>
<li>
<p>点密集化：</p>
<ul>
<li>在具有大梯度的区域分裂点或克隆点。这些区域通常表示高变化率或复杂细节区域，因此需要更多的点来准确表示。对于克隆，创建高斯的复制体并朝着位置梯度移动。对于分裂，用两个较小的高斯替换一个大高斯，按照特定因子减小它们的尺度。</li>
</ul>
</li>
<li>
<p>点的剪枝：</p>
<ul>
<li>移除那些α值非常低的点。如果一个点的透明度非常高，表示其对最终渲染的贡献很小，因此可以安全地移除这些点以减少计算复杂度。</li>
</ul>
</li>
<li>
<p><img loading="lazy" src="./assets/%28null%29-20240523202806461.%28null%29#center" alt="img"  />
</p>
</li>
</ol>
</li>
</ol>
<h3 id="优化实现细节反向传播计算梯度">优化：实现细节（反向传播计算梯度）<a hidden class="anchor" aria-hidden="true" href="#优化实现细节反向传播计算梯度">#</a></h3>
<p>给定标量损失 $\mathcal{L}$ 相对于输出图像每个像素的梯度，我们使用标准链式法则将梯度向后传播到原始输入参数。</p>
<ul>
<li>
<p>Frobenius 内积</p>
<ul>
<li>
<p>在下面的推导中，我们将使用 Frobenius 内积来导出矩阵的导数：</p>
</li>
<li>
$$\langle X, Y \rangle = \text{Tr}(X^T Y) = \text{vec}(X)^T \text{vec}(Y) = \in \mathbb{R},$$
</li>
<li>
<p>它可以被看作是矩阵点积。Frobenius 内积具有以下性质：</p>
</li>
<li>
$$\begin{aligned}    \langle X, Y \rangle &= \langle Y, X \rangle, \\    \langle X, Y \rangle &= \langle X^T, Y^T \rangle, \\    \langle X, YZ \rangle &= \langle Y^T X, Z \rangle = \langle X Z^T, Y \rangle, \\    \langle X, Y + Z \rangle &= \langle X, Y \rangle + \langle X, Z \rangle. \end{aligned}$$
</li>
<li>
<p>假设我们有一个标量函数 $f$ 使 $X\in \mathbb{R}^{m \times n}$，且 $X = A$，其中 $A \in \mathbb{R}^{m \times p}$ 和 $Y \in \mathbb{R}^{p \times n}$。我们可以写出 $f$ 相对于任意标量 $x \in \mathbb{R}$ 的梯度：</p>
</li>
<li>
$$\frac{\partial f}{\partial x} = \left\langle \frac{\partial f}{\partial X}, \frac{\partial X}{\partial x} \right\rangle,$$
</li>
<li>
<p>我们使用简写：</p>
</li>
<li>
$$\partial f = \left\langle \frac{\partial f}{\partial X}, \partial X \right\rangle.$$
</li>
<li>
<p>这里，$\frac{\partial f}{\partial x} \in \mathbb{R}$，$\frac{\partial f}{\partial X} \in \mathbb{R}^{m \times n}$，和 $\frac{\partial X}{\partial x} \in \mathbb{R}^{m \times n}$。</p>
</li>
<li>
<p>在这种情况下，继续使用链式法则非常简单。设 $G = \frac{\partial f}{\partial X$，我们有：</p>
</li>
<li>
$$\begin{aligned}    \frac{\partial f}{\partial x} &= \left\langle G, \frac{\partial (AY)}{\partial x} \right\rangle \\    &= \left\langle G, \frac{\partial A}{\partial x} Y \right\rangle + \left\langle G, A \frac{\partial Y}{\partial x} \right\rangle \\    &= \left\langle G Y^T, \frac{\partial A}{\partial x} \right\rangle + \left\langle A^T G, \frac{\partial Y}{\partial x} \right\rangle. \end{aligned}$$
</li>
<li>
<p>从这里，我们可以得到 $f$ 相对于 $A$ 和 $Y$ 的梯度的元素：</p>
</li>
<li>
$$\frac{\partial f}{\partial A} = G Y^T \in \mathbb{R}^{m \times p}, \quad \frac{\partial f}{\partial Y} = A^T G \in \mathbb{R}^{p \times n}.$$
</li>
</ul>
</li>
</ul>
<h4 id="高斯分布深度合成的梯度计算">高斯分布深度合成的梯度计算<a hidden class="anchor" aria-hidden="true" href="#高斯分布深度合成的梯度计算">#</a></h4>
<p>我们从将像素 $i$ 的损失梯度向后传播到贡献该像素的高斯分布开始。具体来说，对于像素 $i$ 贡献的高斯分布 $i$，我们计算颜色 $\frac{\partial \mathcal{L}}{\partial c_n} \in \mathbb{R^3}$、不透明度 $\frac{\partial \mathcal{L}}{\partial o_n} \in \mathbb{R}$、二维均值 $\frac{\partial \mathcal{L}}{\partial \mu_n'} \in \mathbb{R}^2$ 和二维协方差 $\frac{\partial \mathcal{L}}{\partial \Sigma_n'} \in \mathbb{R}^{2 \times 2}$ 的梯度。</p>
<ol>
<li>
<p>对于每个通道 $k$的颜色，我们有：</p>
<ol>
<li>
$$\frac{\partial C_i(k)}{\partial c_n(k)} = \alpha_n \cdot T_n$$
</li>
<li>
<p>我们保存正向传播过程中计算的最终 $T_N$ 值，并在反向传播过程中计算下一个 $T_{n-1}$ 值：</p>
</li>
<li>
$$T_{n-1} = \frac{T_n}{1 - \alpha_{n-1}}$$
</li>
<li>
<p>对于每个通道 $k$上 $\alpha$ 的梯度，我们有标量梯度：</p>
</li>
<li>
$$\frac{\partial C_i(k)}{\partial \alpha_n} = c_n(k) \cdot T_n - \frac{S_n(k)}{1 - \alpha_n}$$
</li>
<li>
<p>其中，</p>
$$S_n = \sum_{m>n} c_m \alpha_m T_m$$
</li>
<li>
<p>我们可以在反向传播过程中计算 $S_{n-1}$：</p>
</li>
<li>
$$S_N(k) = 0$$
</li>
<li>
$$S_{n-1}(k) = c_n(k)\alpha_n T_n + S_n(k)$$
</li>
</ol>
</li>
<li>
<p>对于不透明度$o$和 $\sigma$：</p>
<ol>
<li>
<p>我们有标量梯度：</p>
</li>
<li>
$$\frac{\partial \alpha_n}{\partial o_n} = \exp(-\sigma_n), \quad \frac{\partial \alpha_n}{\partial \sigma_n} = -o_n \exp(-\sigma_n)$$
</li>
</ol>
</li>
<li>
<p>对于二维均值：</p>
<ol>
<li>
<p>我们有雅可比矩阵：</p>
</li>
<li>
$$\frac{\partial \sigma_n}{\partial \mu_n'} =  \frac{\partial \sigma_n}{\partial \Delta_n} = \Sigma_n'^{-1} \Delta_n \in \mathbb{R}^2$$
</li>
</ol>
</li>
<li>
<p>对于二维协方差：</p>
<ol>
<li>
<p>我们令 $Y = \Sigma_n'^{-1}$，其雅可比矩阵从 $\sigma_n$ 直接得出：</p>
</li>
<li>
$$\frac{\partial \sigma_n}{\partial Y} = \frac{1}{2} \Delta_n \Delta_n^T \in \mathbb{R}^{2 \times 2}$$
</li>
<li>
<p>为了继续通过 $Y \in \mathbb{R}^{2 \times 2}$ 进行反向传播，我们令 $G = \frac{\partial \sigma_n}{\partial Y}$ 并写出相对于标量变量 $x$ 的梯度：</p>
</li>
<li>
$$\frac{\partial \sigma_n}{\partial x} = \langle G, \frac{\partial Y}{\partial x} \rangle$$
</li>
<li>
<p>我们使用 [Petersen et al., 2008, Dwyer and McPhail, 1948] 的等式，得到：</p>
</li>
<li>
$$\begin{aligned}\frac{\partial \sigma_n}{\partial x} = \langle G, -Y \frac{\partial \Sigma_n'^{-1}}{\partial x} Y \rangle \\ = \langle -Y^T G Y^T, \frac{\partial \Sigma_n'}{\partial x} \rangle \end{aligned}$$
</li>
<li>
<p>因此，相对于 $\Sigma_n$ 的梯度为：</p>
</li>
<li>
$$\frac{\partial \sigma_n}{\partial \Sigma_n'} = -\frac{1}{2} \Sigma_n'^{-1} \Delta_n \Delta_n^T \Sigma_n'^{-1}$$
</li>
</ol>
</li>
</ol>
<h4 id="高斯分布投影的梯度计算2d-3d">高斯分布投影的梯度计算（2D-&gt;3D）<a hidden class="anchor" aria-hidden="true" href="#高斯分布投影的梯度计算2d-3d">#</a></h4>
<p>给定损失函数 $\mathcal{L}$ 相对于投影后的二维均值 $\mu$ 和协方差 $\Sigma$ 的梯度，我们可以继续反向传播单个高斯分布的三维均值 $\m$ 和协方差 $\Sigm$ 的梯度。在此，我们一次只处理一个高斯分布，因此省略下标 𝑛，并通过$\begin{array}{l}\frac{\partial\mathcal{L}}{\partial\mu'}\in\mathbb{R}^2，\frac{\partial\mathcal{L}}{\partial\Sigma'}\in\mathbb{R}^{2\times2}\end{array}$计算梯度$\begin{array}{l}\frac{\partial\mathcal{L}}{\partial\mu}\in\mathbb{R}^3，\frac{\partial\mathcal{L}}{\partial\Sigma}\in\mathbb{R}^{3\times3}\end{array}$</p>
<ol>
<li>
<p>计算二维均值 $\mu$ 对相机坐标 $t \in \mathbb{R}^4$ 和二维协方差 $\Sigma'$ 对三维协方差 $\Sigma$ 及相机坐标 $t$的梯度贡献。</p>
<ol>
<li>
<blockquote>
<p>注意，$\mu$ 和 $\Sigma$ 都对 $t$ 的梯度有贡献</p>
</blockquote>
</li>
<li>
$$\frac{\partial\mathcal{L}}{\partial t_i}=\frac{\partial\mathcal{L}_{\mu^{\prime}}}{\partial t_i}+\frac{\partial\mathcal{L}_{\Sigma^{\prime}}}{\partial t_i}=\frac{\partial\mathcal{L}}{\partial\mu^{\prime}}\frac{\partial\mu^{\prime}}{\partial t_i}+\langle\frac{\partial\mathcal{L}}{\partial\Sigma^{\prime}},\frac{\partial\Sigma^{\prime}}{\partial t_i}\rangle$$
</li>
<li>
<p>对于二维均值 $\mu$，我们有：</p>
<ul>
<li>$$\frac{\partial\mathcal{L}_{\mu^{\prime}}}{\partial t}=\frac12P^\top\begin{bmatrix}w/t_w&0&0&-w\cdot t_x/t_w^2\\0&h/t_w&0&-w\cdot t_y/t_w^2\end{bmatrix}^\top\frac{\partial\mathcal{L}}{\partial\mu^{\prime}}$$</li>
</ul>
</li>
<li>
<p>对于二维协方差 $\Sigma'$ 对 $\Sigma$ 和 $t$ 的梯度贡献，$\Sigma'=T\Sigma T^\top$。设 $G = \frac{\partial \mathcal{L}}{\partial \Sigma'}$，我们有：</p>
<ul>
<li>$\begin{aligned}\partial\mathcal{L}_{\Sigma^{\prime}}&=\langle G,\partial\Sigma^{\prime}\rangle\\&=\langle G,(\partial T)\Sigma T^\top+T(\partial\Sigma)T^\top+T\Sigma(\partial T^\top)\rangle\\&=\langle GT\Sigma^\top,\partial T\rangle+\langle T^\top GT,\partial\Sigma\rangle+\langle G^\top T\Sigma,\partial T\rangle\\&=\langle GT\Sigma^\top+G^\top T\Sigma,\partial T\rangle+\langle T^\top GT,\partial\Sigma\rangle.\end{aligned}$</li>
</ul>
</li>
</ol>
</li>
<li>
<p>计算相对于协方差矩阵 Σ 的梯度，</p>
<ol>
<li>
$$\frac{\partial \mathcal{L}}{\partial \Sigma} = T^T \frac{\partial \mathcal{L}}{\partial \Sigma'} T$$
</li>
<li>
<p>我们继续通过 $T = J R_{cw} \in \mathbb{R}^{2 \times 3}$ 传播梯度，对于 $J$ 的梯度，令：</p>
</li>
<li>
$$\partial\mathcal{L}=\langle\frac{\partial\mathcal{L}}{\partial T},(\partial J)R_{\mathrm{cw}}\rangle=\langle\frac{\partial\mathcal{L}}{\partial T}R_{\mathrm{cw}}^\top,\partial J\rangle,\quad\mathrm{where~}\frac{\partial\mathcal{L}}{\partial T}=\frac{\partial\mathcal{L}}{\partial\Sigma^{\prime}}T\Sigma^\top+\frac{\partial\mathcal{L}}{\partial\Sigma^{\prime}}^\top T\Sigma$$
</li>
<li>
<p>我们继续通过 $J$ 对相机坐标 $t \in \mathbb{R}^4$ 的贡献进行反向传播：</p>
</li>
<li>
<p>$\frac{\partial J}{\partial t_x}=\begin{bmatrix}0&0&-f_x/t_z^2\\0&0&0\end{bmatrix},\quad\frac{\partial J}{\partial t_y}=\begin{bmatrix}0&0&0\\0&0&-f_y/t_z^2\end{bmatrix},\quad\frac{\partial J}{\partial t_z}=\begin{bmatrix}-f_x/t_z^2&0&2f_xt_x/t_z^3\\0&-f_y/t_z^2&2f_yt_y/t_z^3\end{bmatrix},\quad\frac{\partial J}{\partial t_w}=\mathbf{0}^{2\times3}$</p>
</li>
<li>
<p>我们现在可以将两个梯度 $\frac{\partial \mathcal{L_{\mu'}}}{\partial t}$ 和 $\frac{\partial \mathcal{L_{\Sigma'}}}{\partial t}$ 合并为 $G = \frac{\partial \mathcal{L}}{\partial t}$ 并计算相对于三维均值 $\mu$和视图矩阵 $T_{cw}$ 的全梯度。且有$t=T_\text{cw}q,\text{ where }q=\begin{bmatrix}\mu&1\end{bmatrix}^\top$</p>
</li>
<li>
$$\begin{aligned}\partial\mathcal{L}&=\langle G,\partial t\rangle=\langle G,\partial(T_\text{cw}q)\rangle\\&=\langle Gq^\top,\partial T_{\mathrm{cw}}\rangle+\langle T_{\mathrm{cw}}^\top G,\partial q\rangle\end{aligned}$$
</li>
<li>
<p>相对于 $\mu$ 和 $T_{cw}$ 的梯度：</p>
</li>
<li>
$$\frac{\partial\mathcal{L}}{\partial T_{\mathrm{cw}}}=\frac{\partial\mathcal{L}}{\partial t}q^\top\in\mathbb{R}^{4\times4},\quad\frac{\partial\mathcal{L}}{\partial\mu}=R_{\mathrm{cw}}^\top\begin{bmatrix}\frac{\partial\mathcal{L}}{\partial t_x}&\frac{\partial\mathcal{L}}{\partial t_y}&\frac{\partial\mathcal{L}}{\partial t_z}\end{bmatrix}^\top\in\mathbb{R}^3$$
</li>
</ol>
</li>
<li>
<p>尺度和旋转梯度</p>
<ol>
<li>
<p>现在我们有 $\Sigma = M M^3$ 和 $\frac{\partial \mathcal{L}}{\partial \Sigma} $。设 $G = \frac{\partial \mathcal{L}}{\partial \Sigma}$，我们有：</p>
</li>
<li>
$$\begin{aligned}\partial\mathcal{L}&=\langle G,\partial\Sigma\rangle\\&=\langle G,(\partial M)M^\top+M(\partial M^\top)\rangle\\&=\langle GM+G^\top M,\partial M\rangle\end{aligned}$$
</li>
<li>
<p>这给我们：</p>
</li>
<li>
$$\frac{\partial \mathcal{L}}{\partial M} = \frac{\partial \mathcal{L}}{\partial \Sigma} M + \frac{\partial \mathcal{L}}{\partial \Sigma}^T M $$
</li>
<li>
<p>现在我们有 $M = R $，并且 $G = \frac{\partial \mathcal{L}}{\partial M}$，所以：</p>
</li>
<li>
$$\begin{aligned}\partial\mathcal{L}&=\langle G,\partial M\rangle\\&=\langle G,(\partial R)S\rangle+\langle G,R(\partial S)\rangle\\&=\langle GS^\top,\partial R\rangle+\langle R^\top G,\partial S\rangle\end{aligned}$$
</li>
<li>
<p>这给我们：</p>
</li>
<li>
$$\frac{\partial \mathcal{L}}{\partial R} = \frac{\partial \mathcal{L}}{\partial M} S^T, \quad \frac{\partial \mathcal{L}}{\partial S} = R^T \frac{\partial \mathcal{L}}{\partial M} $$
</li>
<li>
<p>旋转矩阵 $R$ 关于四元数参数 $q = (w, x, y, z)$ 的雅可比矩阵是：</p>
</li>
<li>
$$\frac{\partial R}{\partial w} = 2 \begin{bmatrix} 0 & -z & y \\ z & 0 & -x \\ -y & x & 0 \end{bmatrix}, \quad \frac{\partial R}{\partial x} = 2 \begin{bmatrix} 0 & y & z \\ y & -2x & -w \\ z & w & -2x \end{bmatrix}$$
</li>
<li>
$$\frac{\partial R}{\partial y} = 2 \begin{bmatrix} -2y & x & w \\ x & 0 & z \\ w & z & -2y \end{bmatrix}, \quad \frac{\partial R}{\partial z} = 2 \begin{bmatrix} -2z & -w & x \\ w & -2z & y \\ x & y & 0 \end{bmatrix}$$
</li>
<li>
<p>尺度矩阵 $S$ 关于尺度参数 $s = (s_x, s_y, s_z)$ 的雅可比矩阵是：</p>
</li>
<li>
$$\frac{\partial S}{\partial s_j} = \delta_{ij}$$
</li>
<li>
<p>其中选择相应的对角元素 $\frac{\partial \mathcal{L}}{\partial S}$。</p>
</li>
</ol>
</li>
</ol>
<h3 id="ex球谐函数">EX：球谐函数<a hidden class="anchor" aria-hidden="true" href="#ex球谐函数">#</a></h3>
<blockquote>
<p>球谐函数在3DGS中并不是必须的</p>
</blockquote>
<p><img loading="lazy" src="./assets/%28null%29-20240523202811474.%28null%29#center" alt="img"  />
</p>
<ul>
<li>
<p><strong>球谐函数（Spherical Harmonics, SH）</strong></p>
<ul>
<li>
<p>球谐函数被用来表示视角依赖的颜色，这样可以更好地处理非朗伯反射（如金属表面的镜面反射）。具体来说，通过限制自由度 $\ell_{\text{max}}$，每个颜色（红、绿、蓝）可以表示为前$ \ell\_{\text{max}}$ 个球谐函数的线性组合。</p>
</li>
<li>
<p>球谐函数是一组定义在球面上的特殊函数，通过选择正整数 $\ell$ 和 $-\ell \leq m \leq \ell$ 的一对 $(\ell, m)$，可以从一个通用公式中导出这些函数。</p>
</li>
</ul>
</li>
<li>
<p><strong>公式解释</strong></p>
<ul>
<li>
<p>球谐函数的通用公式为：</p>
</li>
<li>
$$Y_\ell^m (\theta, \phi) = (-1)^m \sqrt{\frac{(2\ell + 1)(\ell - m)!}{4\pi (\ell + m)!}} P_\ell^m (\cos \theta) e^{im\phi}$$
</li>
<li>
<p>其中：</p>
</li>
<li>
<p>$\ell $和 m 是整数，$\ell \geq 0，-\ell \leq m \leq \ell$。</p>
</li>
<li>
<p>$\theta$ 是极角（通常在0到$\pi$之间），$\phi$ 是方位角（通常在0到$2\pi$之间）。</p>
</li>
<li>
<p>$P_\ell^m$ 是缔合勒让德多项式（Associated Legendre Polynomials）。</p>
</li>
<li>
<p><strong>球谐函数的性质</strong></p>
<ul>
<li><strong>正交性</strong>： 球谐函数是正交的，这意味着在球面上的任意两个不同的球谐函数在积分意义下相互独立。</li>
<li><strong>归一化</strong>： 球谐函数是归一化的，因此可以形成球面上函数空间的正交基。</li>
<li><strong>简化</strong>： 对于小的$\ell $值，球谐函数公式会显著简化。例如，当 $\ell $ = 0 时，球谐函数是一个常数，当 $\ell $ = 1 时，球谐函数也是相对简单的形式。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>颜色表示</strong></p>
<ul>
<li>
<p>对于每个三维高斯点，我们希望学习正确的系数，使得从某个方向看该三维点时，它传达的颜色最接近真实颜色。这是通过以下步骤实现的：</p>
</li>
<li>
<p><strong>选择最大自由度</strong>：</p>
<ol>
<li>选择一个适当的$ \ell\_{\text{max}}$ 值，以限制球谐函数的数量。</li>
</ol>
</li>
<li>
<p><strong>线性组合</strong>：</p>
<ol>
<li>每种颜色（红、绿、蓝）都表示为前$ \ell\_{\text{max}} $个球谐函数的线性组合。对于每个三维高斯点，学习这些线性组合的系数。</li>
</ol>
</li>
<li>
<p><strong>视角依赖的颜色计算</strong>：</p>
<ol>
<li>给定一个观察方向，使用球谐函数和学习到的系数计算该方向上的颜色。</li>
</ol>
</li>
</ul>
</li>
<li>
<p><strong>示例</strong></p>
<ul>
<li>
<p>假设我们选择 $\ell_{\text{max}}=2$，则有 5 个球谐函数（$\ell $= 0, 1, 2 对应的各个 m 值）。我们需要为每个颜色学习 5 个系数。假设对于某个高斯点，这些系数为 $c_{r,i}, c_{g,i}, c_{b,i}$（红、绿、蓝）。</p>
</li>
<li>
<p>对于一个特定的观察方向 $(\theta, \phi)$，我们可以计算该方向上的颜色：</p>
</li>
<li>
$$\text{Color}(\theta, \phi) = \left( \sum_{i=1}^5 c_{r,i} Y_i(\theta, \phi), \sum_{i=1}^5 c_{g,i} Y_i(\theta, \phi), \sum_{i=1}^5 c_{b,i} Y_i(\theta, \phi) \right)$$
</li>
</ul>
</li>
<li>
<p><strong>总结</strong></p>
<ul>
<li>球谐函数提供了一种有效的方法来表示视角依赖的颜色，使得模型能够处理非朗伯反射效果。在具体实现中，通过选择适当的 $\ell_{\text{max}}$，并学习每个颜色的球谐函数系数，可以实现高质量的渲染效果。球谐函数的正交性和归一化性质保证了这种表示的数学稳健性和计算效率。</li>
</ul>
</li>
</ul>
<h2 id="资源消耗">资源消耗<a hidden class="anchor" aria-hidden="true" href="#资源消耗">#</a></h2>
<h3 id="数据准备快">数据准备（快）<a hidden class="anchor" aria-hidden="true" href="#数据准备快">#</a></h3>
<ul>
<li>使用COLMAP从图像集合中提取SfM信息</li>
</ul>
<h3 id="训练较慢">训练（较慢）<a hidden class="anchor" aria-hidden="true" href="#训练较慢">#</a></h3>
<table>
<thead>
<tr>
<th>GPU</th>
<th>NVIDIA RTX 4090</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>显存</td>
<td>24 GB</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>场景</td>
<td>drjohnson</td>
<td>playroom</td>
<td>bottle</td>
<td>scene(dynamic)</td>
</tr>
<tr>
<td>图片数量</td>
<td>263</td>
<td>225</td>
<td>48</td>
<td>105</td>
</tr>
<tr>
<td>图片分辨率(px)</td>
<td>1332x876</td>
<td>1264x832</td>
<td>1081x1932</td>
<td>1065x1895</td>
</tr>
<tr>
<td>训练时间</td>
<td>41 min</td>
<td>17 min</td>
<td>17 min</td>
<td>22 min</td>
</tr>
<tr>
<td><code>.ply</code> 文件大小（7000 次迭代）</td>
<td>423 MB（1,789,615个顶点）</td>
<td>403MB（1,618,690个顶点）</td>
<td>48MB</td>
<td>136MB</td>
</tr>
<tr>
<td><code>.ply</code> 文件大小（30000 次迭代）</td>
<td>812 MB（3,433,974个顶点）</td>
<td>587MB（2,356,284个顶点）</td>
<td>54MB</td>
<td>324MB</td>
</tr>
</tbody>
</table>
<blockquote>
<p>1个顶点约0.25KB</p>
<ul>
<li>高斯核均值信息$\mu$：x, y, z 位置信息</li>
<li>协方差矩阵$\Sigma$：3x3矩阵，表示高斯核的缩放+旋转</li>
<li>透明度$\alpha$</li>
<li>SH球谐函数颜色信息：48个（只用到前4阶）</li>
</ul>
</blockquote>
<h3 id="渲染快">渲染（快）<a hidden class="anchor" aria-hidden="true" href="#渲染快">#</a></h3>
<table>
<thead>
<tr>
<th>GPU</th>
<th>Apple M1 Pro</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Render window</td>
<td>1920x1080（1080p）</td>
<td>2268x1420（~2K）</td>
</tr>
<tr>
<td>FPS（2M～3M顶点）</td>
<td>50～60 FPS</td>
<td>20～30 FPS</td>
</tr>
<tr>
<td>FPS（1M～2M顶点）</td>
<td>60+ FPS</td>
<td>30～40 FPS</td>
</tr>
</tbody>
</table>
<blockquote>
<p>由于mac不支持3DGS源代码提供的SIMR viewer，因此目前采用的是基于WebGL的方式（<a href="https://playcanvas.com/supersplat/editor">SuperSplat</a>，<a href="https://projects.markkellogg.org/threejs/demo_gaussian_splats_3d.php">Three.js</a>），如果在windows平台上通过官方渲染程序运行应该会更快。</p>
</blockquote>
<h2 id="代码分析">代码分析<a hidden class="anchor" aria-hidden="true" href="#代码分析">#</a></h2>
<h2 id="局限性">局限性<a hidden class="anchor" aria-hidden="true" href="#局限性">#</a></h2>
<p>尽管高斯分布渲染（Gaussian Splatting）在整体上取得了出色的结果和令人印象深刻的渲染速度，但这种表示方法的简单性也带来了一些代价。以下是主要的局限性和需要考虑的问题：</p>
<h3 id="密集化启发式">密集化启发式<a hidden class="anchor" aria-hidden="true" href="#密集化启发式">#</a></h3>
<p>在优化过程中，引入了各种密集化启发式，以防止模型出现“破损”的高斯点（如过大、过长或冗余的点）。这些密集化措施对于保持模型的稳定性和一致性至关重要。如果没有这些措施，模型可能会在优化过程中产生问题。</p>
<ul>
<li><strong>过大或过长的高斯点</strong>：如果高斯点的尺寸过大或过长，可能会导致渲染结果失真。</li>
<li><strong>冗余的高斯点</strong>：过多的冗余点会增加计算复杂度，而不会显著提高渲染质量。</li>
</ul>
<p>这些问题在处理超出新视角渲染任务范围的其他任务时可能会进一步放大。</p>
<h3 id="离散表示的选择">离散表示的选择<a hidden class="anchor" aria-hidden="true" href="#离散表示的选择">#</a></h3>
<p>选择离散表示而非连续表示意味着丧失了多层感知机（MLP）的归纳偏置。在 NeRFs 中，MLP 执行隐式插值，平滑处理视角之间的可能不一致性，而三维高斯点对这些不一致性更加敏感，导致上述问题的出现。</p>
<ul>
<li><strong>MLP</strong> <strong>的插值和平滑</strong>：在 NeRF 中，MLP 可以通过插值和平滑减少视角之间的差异。</li>
<li><strong>三维高斯点的敏感性</strong>：三维高斯点在处理这些不一致性时更容易出现问题，导致渲染结果不如 NeRF 平滑。</li>
</ul>
<h3 id="继承的伪影问题">继承的伪影问题<a hidden class="anchor" aria-hidden="true" href="#继承的伪影问题">#</a></h3>
<p>高斯分布渲染继承了一些 NeRF 中存在的已知伪影，这些伪影源于共享的图像形成模型。例如：</p>
<ul>
<li><strong>在较少或未见区域的较低质量</strong>：在训练数据中较少或未出现的区域，渲染质量可能较低。</li>
<li><strong>靠近图像平面的浮动伪影</strong>：在靠近图像平面的区域，可能会出现浮动伪影。</li>
</ul>
<p>这些问题在高斯分布渲染和 NeRF 中都是存在的，源于它们使用的相似图像形成模型。</p>
<h3 id="检查点文件大小">检查点文件大小<a hidden class="anchor" aria-hidden="true" href="#检查点文件大小">#</a></h3>
<p>检查点文件的大小是另一个需要考虑的属性。尽管新视角渲染尚未被部署到边缘设备，但从磁盘空间的角度来看，三维点的数量和流行的 NeRF MLP 架构占用了相同数量级的磁盘空间，平均而言，高斯分布渲染的文件大小比 NeRF 略大几倍。</p>
<ul>
<li><strong>磁盘空间占用</strong>：高斯分布渲染由于三维点的数量较多，文件大小略大于 NeRF。</li>
<li><strong>部署考虑</strong>：虽然目前部署到边缘设备的需求不大，但未来可能需要考虑文件大小对部署的影响。</li>
</ul>
<h1 id="数据集">数据集<a hidden class="anchor" aria-hidden="true" href="#数据集">#</a></h1>
<table>
<thead>
<tr>
<th>数据集名称</th>
<th>描述</th>
<th>来源</th>
</tr>
</thead>
<tbody>
<tr>
<td>LLFF</td>
<td>本地光场融合（LLFF）数据集包括自然场景的合成图像和真实图像。合成图像由SUNCG和UnrealCV生成，而真实图像包括使用手持手机拍摄的24个场景。</td>
<td><a href="https://bmild.github.io/llff/">链接</a></td>
</tr>
<tr>
<td>NeRF</td>
<td>神经辐射场（NeRF）数据集包含复杂场景的合成渲染和真实图像。它包括漫射合成360°、真实合成360°和复杂场景的真实图像。</td>
<td><a href="https://www.matthewtancik.com/nerf">链接</a></td>
</tr>
<tr>
<td>DONeRF</td>
<td>DONeRF数据集包括使用Blender和Cycles路径追踪器生成的合成数据，每个场景渲染300张图像。</td>
<td><a href="https://depthoraclenerf.github.io/">链接</a></td>
</tr>
<tr>
<td>X3D</td>
<td>X3D数据集包括15个专用于X射线3D重建的场景，涵盖医学、生物学、安全和工业应用。</td>
<td><a href="https://github.com/caiyuanhao1998/SAX-NeRF">链接</a></td>
</tr>
<tr>
<td>RTMV</td>
<td>RTMV是一个用于新视图合成的合成数据集，包括通过光线追踪生成的300,000张图像，涵盖2,000个场景。</td>
<td><a href="https://www.cs.umd.edu/~mmeshry/projects/rtmv/">链接</a></td>
</tr>
<tr>
<td>Tanks&amp;Temples</td>
<td>Tanks&amp;Temples数据集是综合性的，提供了用于基于图像的3D重建管道的中级和高级测试数据集。</td>
<td><a href="https://www.tanksandtemples.org/">链接</a></td>
</tr>
<tr>
<td>RealEstate10K</td>
<td>RealEstate10K是一个大型数据集，从10,000个YouTube视频中获取相机位姿，提供通过SLAM和捆绑调整算法获得的轨迹。</td>
<td><a href="https://google.github.io/realestate10k/">链接</a></td>
</tr>
<tr>
<td>ACID</td>
<td>空中海岸线影像数据集（ACID）数据集专注于基于单一图像的延长相机轨迹生成新视图，采用几何和图像合成的混合方法。</td>
<td><a href="https://infinite-nature.github.io/">链接</a></td>
</tr>
<tr>
<td>SWORD</td>
<td>&lsquo;包含遮挡区域的场景&rsquo;数据集（SWORD）包含1,500个训练视频和290个测试视频，强调用于鲁棒模型训练的近物体和遮挡。</td>
<td><a href="https://samsunglabs.github.io/StereoLayers/">链接</a></td>
</tr>
<tr>
<td>Mip-NeRF 360</td>
<td>Mip-NeRF 360数据集扩展了Mip-NeRF，具有非线性参数化、在线非蒸馏和用于无边界场景的畸变基正则化器。</td>
<td><a href="https://jonbarron.info/mipnerf360/">链接</a></td>
</tr>
<tr>
<td>Deep Blending</td>
<td>用于自由视点基于图像渲染的深度混合数据集包括9个场景，这些场景使用立体相机装备捕获并使用COLMAP和RealityCapture重建。</td>
<td><a href="http://visual.cs.ucl.ac.uk/pubs/deepblending/">链接</a></td>
</tr>
<tr>
<td>DTU</td>
<td>DTU数据集是多视点立体数据，具有精确的相机定位、结构光扫描仪和不同照明条件的多样化场景。</td>
<td><a href="https://roboimagedata.compute.dtu.dk/?page_id=36">链接</a></td>
</tr>
<tr>
<td>ScanNet</td>
<td>ScanNet是一个室内RGB-D数据集，包含1513个标注扫描，提供90%的表面覆盖率和多样化的3D场景理解任务。</td>
<td><a href="http://www.scan-net.org/">链接</a></td>
</tr>
<tr>
<td>ShapeNet</td>
<td>ShapeNet是一个大型3D CAD模型库，对NeRF模型来说非常有价值，强调基于对象的语义标签。</td>
<td><a href="https://shapenet.org/">链接</a></td>
</tr>
<tr>
<td>Matterport 3D</td>
<td>Matterport-3D数据集包括来自90个建筑规模场景的10,800个全景图视图，具有深度、语义和实例注释。</td>
<td><a href="https://niessner.github.io/Matterport/">链接</a></td>
</tr>
<tr>
<td>Replica</td>
<td>Replica数据集是一个真实的室内数据集，包含18个场景和35个房间，具有手动调整、语义注释以及基于类和基于实例的标签。</td>
<td><a href="https://github.com/facebookresearch/Replica-Dataset">链接</a></td>
</tr>
<tr>
<td>Plenoptic Video</td>
<td>全光视频数据集包含使用全光相机捕获的3D视频，提供逼真和沉浸式的3D体验。</td>
<td><a href="https://neural-3d-video.github.io/">链接</a></td>
</tr>
<tr>
<td>Panoptic</td>
<td>CMU全景数据集包含超过150万个实例的3D姿态注释，这些实例出现在社交活动中，并使用同步摄像机捕获，场景多样。</td>
<td><a href="http://domedb.perception.cs.cmu.edu/">链接</a></td>
</tr>
</tbody>
</table>
<h1 id="研究现状">研究现状<a hidden class="anchor" aria-hidden="true" href="#研究现状">#</a></h1>
<p><img loading="lazy" src="./assets/%28null%29-20240523202818285.%28null%29#center" alt="img"  />
</p>
<h2 id="功能性">功能性<a hidden class="anchor" aria-hidden="true" href="#功能性">#</a></h2>
<blockquote>
<p>拓展3DGS本身的能力</p>
</blockquote>
<h3 id="动态和变形">动态和变形<a hidden class="anchor" aria-hidden="true" href="#动态和变形">#</a></h3>
<blockquote>
<ul>
<li>拓展的参数列表
<ul>
<li><strong>在时间</strong> $ t$的 3D 位置：$[x(t), y(t), z(t)]^\top \in \mathbb{R}^3 $</li>
<li><strong>在时间</strong> $ t$的 3D 旋转，由四元数表示：$[q_x(t), q_y(t), q_z(t), q_w(t)]^\top \in \mathbb{R}^4 $</li>
<li><strong>缩放因子</strong>：$[s_x, s_y, s_z]^\top \in \mathbb{R}^3 $</li>
<li><strong>表示颜色的球谐系数，具有自由度 k</strong>：$h \in \mathbb{R}^{3 \times (k + 1)^2} $</li>
<li><strong>不透明度</strong>：$o \in \mathbb{R} $</li>
</ul>
</li>
</ul>
</blockquote>
<ul>
<li>
<p>动态场景追踪</p>
<ul>
<li>
<p><a href="https://dynamic3dgaussians.github.io/">Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis</a></p>
</li>
<li>
<p><a href="https://guanjunwu.github.io/4dgs/">4D Gaussian Splatting for Real-Time Dynamic Scene Rendering（CVPR 2024）</a></p>
</li>
</ul>
</li>
<li>
<p>动态场景编辑</p>
<ul>
<li>
<p><a href="https://control4darxiv.github.io/">Control4D: Efficient 4D Portrait Editing with Text（CVPR 2024）</a></p>
<ul>
<li><a href="https://yihua7.github.io/SC-GS-web/">SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes（CVPR 2024）</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="扩散模型">扩散模型<a hidden class="anchor" aria-hidden="true" href="#扩散模型">#</a></h3>
<ul>
<li>
<p>文生3D</p>
<ul>
<li>
<p><a href="https://taoranyi.com/gaussiandreamer/">GaussianDreamer: Fast Generation from Text to 3D Gaussians by Bridging 2D and 3D Diffusion Models（CVPR 2024）</a></p>
<ul>
<li><img loading="lazy" src="./assets/%28null%29-20240523202823069.%28null%29#center" alt="img"  />
</li>
</ul>
</li>
<li>
<p><a href="https://gsgen3d.github.io/">Gsgen: Text-to-3D using Gaussian Splatting（CVPR 2024）</a></p>
</li>
<li>
<p><a href="https://dreamgaussian.github.io/">DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation</a>（ICLR 2024 Oral）</p>
</li>
</ul>
</li>
<li>
<p>去噪和优化</p>
<ul>
<li><a href="https://www.semanticscholar.org/paper/GaussianDiffusion%3A-3D-Gaussian-Splatting-for-Models-Li-Wang/088d88f44e1f3f4ca7166aba9a363d690981844c">GaussianDiffusion: 3D Gaussian Splatting for Denoising Diffusion Probabilistic Models with Structured Noise</a>
<ul>
<li>利用高斯 Splatting 和 Langevin 动力学扩散模型可加速加速渲染并提高真实感。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="优化和加速">优化和加速<a hidden class="anchor" aria-hidden="true" href="#优化和加速">#</a></h3>
<ul>
<li><a href="https://www.semanticscholar.org/paper/Depth-Regularized-Optimization-for-3D-Gaussian-in-Chung-Oh/631288aabfb2045e9d5befd7c5620fcf2ef22243">Depth-Regularized Optimization for 3D Gaussian Splatting in Few-Shot Images</a></li>
<li><a href="https://www.semanticscholar.org/paper/Compact-3D-Gaussian-Representation-for-Radiance-Lee-Rho/9a898d3ebe03a6bd46176b721bc4bb839fe1cdcb">Compact 3D Gaussian Representation for Radiance Field</a></li>
<li><a href="https://www.semanticscholar.org/paper/EAGLES%3A-Efficient-Accelerated-3D-Gaussians-with-Girish-Gupta/c7deb4a0a031661e6d886a884fabce433d62cc9c">EAGLES: Efficient Accelerated 3D Gaussians with Lightweight EncodingS</a></li>
<li><a href="https://www.semanticscholar.org/paper/COLMAP-Free-3D-Gaussian-Splatting-Fu-Liu/b8eb5493895c8a342cfb176e90f57bc5f483a07c">COLMAP-Free 3D Gaussian Splatting</a></li>
</ul>
<h3 id="渲染和着色">渲染和着色<a hidden class="anchor" aria-hidden="true" href="#渲染和着色">#</a></h3>
<ul>
<li><a href="https://www.semanticscholar.org/paper/Mip-Splatting%3A-Alias-free-3D-Gaussian-Splatting-Yu-Chen/7e305e37b49feb8899ae94f641c4f2d0d01ef054">Mip-Splatting: Alias-free 3D Gaussian Splatting</a></li>
<li><a href="https://www.semanticscholar.org/paper/Relightable-3D-Gaussian%3A-Real-time-Point-Cloud-with-Gao-Gu/4314117988b59c9ae108675e55de9ff8fa9dd9a8">Relightable 3D Gaussian: Real-time Point Cloud Relighting with BRDF Decomposition and Ray Tracing</a></li>
<li><a href="https://www.semanticscholar.org/paper/GS-IR%3A-3D-Gaussian-Splatting-for-Inverse-Rendering-Liang-Zhang/51b93b9a5e5e51d0846f45f54875698ccdd6c231">GS-IR: 3D Gaussian Splatting for Inverse Rendering</a></li>
<li><a href="https://www.semanticscholar.org/paper/Multi-Scale-3D-Gaussian-Splatting-for-Anti-Aliased-Yan-Low/6fc4869263ea4e9dde902d7cd9899436d9826dcc">Multi-Scale 3D Gaussian Splatting for Anti-Aliased Rendering</a></li>
<li><a href="https://www.semanticscholar.org/paper/GaussianShader%3A-3D-Gaussian-Splatting-with-Shading-Jiang-Tu/9420a5e441125271d837983e0532ad7c4f76efa6">GaussianShader: 3D Gaussian Splatting with Shading Functions for Reflective Surfaces</a></li>
<li><a href="https://www.semanticscholar.org/paper/Scaffold-GS%3A-Structured-3D-Gaussians-for-Rendering-Lu-Yu/a294b8632fed59e7079ef6187b0afa532c97ed7f">Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering</a></li>
<li><a href="https://www.semanticscholar.org/paper/FSGS%3A-Real-Time-Few-shot-View-Synthesis-using-Zhu-Fan/51965f41228e35a798c55613c40dd1499584660b">FSGS: Real-Time Few-shot View Synthesis using Gaussian Splatting</a></li>
</ul>
<h3 id="压缩">压缩<a hidden class="anchor" aria-hidden="true" href="#压缩">#</a></h3>
<ul>
<li><a href="https://www.semanticscholar.org/paper/LightGaussian%3A-Unbounded-3D-Gaussian-Compression-Fan-Wang/951facdc297370af63da7f6c36f6b2114dd6b01f">LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and 200+ FPS</a></li>
<li><a href="https://www.semanticscholar.org/paper/Compact3D%3A-Compressing-Gaussian-Splat-Radiance-with-Navaneet-Meibodi/a2511d30a88268f970d37351a7bca2318a49ceac">Compact3D: Compressing Gaussian Splat Radiance Field Models with Vector Quantization</a></li>
</ul>
<h2 id="应用性">应用性<a hidden class="anchor" aria-hidden="true" href="#应用性">#</a></h2>
<blockquote>
<p>3DGS的实际应用</p>
</blockquote>
<h3 id="数字化身">数字化身<a hidden class="anchor" aria-hidden="true" href="#数字化身">#</a></h3>
<ul>
<li>基于铰接式或联合式</li>
<li>可动画化</li>
<li>基于头部</li>
</ul>
<h3 id="slam">SLAM<a hidden class="anchor" aria-hidden="true" href="#slam">#</a></h3>
<h3 id="mesh-提取">Mesh 提取<a hidden class="anchor" aria-hidden="true" href="#mesh-提取">#</a></h3>
<h3 id="可编辑性">可编辑性<a hidden class="anchor" aria-hidden="true" href="#可编辑性">#</a></h3>
<h1 id="参考资料">参考资料<a hidden class="anchor" aria-hidden="true" href="#参考资料">#</a></h1>
<ol>
<li>3DGS概述
<ol>
<li>⭐️ <a href="https://www.bilibili.com/video/BV11e411n79b/?vd_source=896adf0655b4e4dfce84eb5e469215df">3D Gaussian Splatting原理速通（一）～（四）</a>（29 min watch）</li>
<li>⭐️ <a href="https://aras-p.info/blog/2023/09/05/Gaussian-Splatting-is-pretty-cool/">Gaussian Splatting is pretty cool!</a>（10 min read）</li>
<li>⭐️ <a href="https://logessiva.medium.com/understanding-and-exploring-3d-gaussian-splatting-a-comprehensive-overview-b4004f28ef1c">Understanding and Exploring 3D Gaussian Splatting: A Comprehensive Overview</a>（9 min read）</li>
<li><a href="https://3dgstutorial.github.io/">3DGS 官方 Tutorial</a> （2 hours watch）</li>
<li><a href="https://zhuanlan.zhihu.com/p/661569671">NeRF坑浮沉记3D Gaussian Splatting入门</a>（5 min read）</li>
<li><a href="https://zhuanlan.zhihu.com/p/680669616">一文带你入门 3D Gaussian Splatting</a>（10 min read）</li>
</ol>
</li>
<li>原理详解
<ol>
<li>⭐️ <a href="https://towardsdatascience.com/a-comprehensive-overview-of-gaussian-splatting-e7d570081362">A Comprehensive Overview of Gaussian Splatting</a>（12 min read）</li>
<li><a href="https://arxiv.org/pdf/2312.02121">Mathematical Supplement for the gsplat Library</a>（30 min read）</li>
<li><a href="https://medium.com/@AriaLeeNotAriel/numbynum-3d-gaussian-splatting-for-real-time-radiance-field-rendering-kerbl-et-al-60c0b25e5544">NumByNum 3D Gaussian Splatting Reviewed</a>（29 min read）</li>
<li><a href="https://www.cs.umd.edu/~zwicker/publications/EWASplatting-TVCG02.pdf">EWA Splatting</a> （30+ min read）</li>
</ol>
</li>
<li>研究现状</li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="/tags/learning-note/">Learning Note</a></li>
      <li><a href="/tags/deep-learning/">Deep Learning</a></li>
      <li><a href="/tags/computer-vision/">Computer Vision</a></li>
      <li><a href="/tags/3dgs/">3DGS</a></li>
    </ul>
<nav class="paginav">
  <a class="next" href="/posts/recent-advances-in-vision-foundation-models.assets/">
    <span class="title">Next »</span>
    <br>
    <span>Recent Advances in Vision Foundation Models</span>
  </a>
</nav>

  </footer><div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "jay-tech" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="/">Jay Tech</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
